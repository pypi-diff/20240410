# Comparing `tmp/raydp_nightly-2023.9.19.dev0-py3-none-any.whl.zip` & `tmp/raydp_nightly-2024.4.10.dev0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,43 +1,44 @@
-Zip file size: 393202 bytes, number of entries: 41
--rw-r--r--  2.0 unx      902 b- defN 23-Sep-19 00:46 raydp/__init__.py
--rw-r--r--  2.0 unx    10438 b- defN 23-Sep-19 00:46 raydp/context.py
--rw-r--r--  2.0 unx     1380 b- defN 23-Sep-19 00:46 raydp/estimator.py
--rw-r--r--  2.0 unx     2764 b- defN 23-Sep-19 00:46 raydp/ray_cluster_resources.py
--rw-r--r--  2.0 unx     3007 b- defN 23-Sep-19 00:46 raydp/services.py
--rw-r--r--  2.0 unx     7666 b- defN 23-Sep-19 00:46 raydp/utils.py
--rw-r--r--  2.0 unx     1474 b- defN 23-Sep-19 00:46 raydp/versions.py
--rwxr-xr-x  2.0 unx     5090 b- defN 23-Sep-19 00:46 raydp/bin/raydp-submit
--rw-r--r--  2.0 unx   286937 b- defN 23-Sep-19 00:47 raydp/jars/raydp-1.7.0-SNAPSHOT.jar
--rw-r--r--  2.0 unx     7071 b- defN 23-Sep-19 00:47 raydp/jars/raydp-agent-1.7.0-SNAPSHOT.jar
--rw-r--r--  2.0 unx    16000 b- defN 23-Sep-19 00:47 raydp/jars/raydp-shims-common-1.7.0-SNAPSHOT.jar
--rw-r--r--  2.0 unx    14050 b- defN 23-Sep-19 00:47 raydp/jars/raydp-shims-spark322-1.7.0-SNAPSHOT.jar
--rw-r--r--  2.0 unx    15151 b- defN 23-Sep-19 00:47 raydp/jars/raydp-shims-spark330-1.7.0-SNAPSHOT.jar
--rw-r--r--  2.0 unx    16004 b- defN 23-Sep-19 00:48 raydp/jars/raydp-shims-spark340-1.7.0-SNAPSHOT.jar
--rw-r--r--  2.0 unx     4396 b- defN 23-Sep-19 00:46 raydp/mpi/__init__.py
--rw-r--r--  2.0 unx     1122 b- defN 23-Sep-19 00:46 raydp/mpi/constants.py
--rw-r--r--  2.0 unx    15624 b- defN 23-Sep-19 00:46 raydp/mpi/mpi_job.py
--rw-r--r--  2.0 unx     8304 b- defN 23-Sep-19 00:46 raydp/mpi/mpi_worker.py
--rw-r--r--  2.0 unx     4044 b- defN 23-Sep-19 00:46 raydp/mpi/utils.py
--rw-r--r--  2.0 unx      893 b- defN 23-Sep-19 00:46 raydp/mpi/network/__init__.py
--rw-r--r--  2.0 unx    15133 b- defN 23-Sep-19 00:46 raydp/mpi/network/network_pb2.py
--rw-r--r--  2.0 unx     8980 b- defN 23-Sep-19 00:46 raydp/mpi/network/network_pb2_grpc.py
--rw-r--r--  2.0 unx     1361 b- defN 23-Sep-19 00:46 raydp/spark/__init__.py
--rw-r--r--  2.0 unx    25574 b- defN 23-Sep-19 00:46 raydp/spark/dataset.py
--rw-r--r--  2.0 unx     1535 b- defN 23-Sep-19 00:46 raydp/spark/interfaces.py
--rw-r--r--  2.0 unx     1141 b- defN 23-Sep-19 00:46 raydp/spark/parallel_iterator_worker.py
--rw-r--r--  2.0 unx     9540 b- defN 23-Sep-19 00:46 raydp/spark/ray_cluster.py
--rw-r--r--  2.0 unx     9286 b- defN 23-Sep-19 00:46 raydp/spark/ray_cluster_master.py
--rw-r--r--  2.0 unx      847 b- defN 23-Sep-19 00:46 raydp/tf/__init__.py
--rw-r--r--  2.0 unx    13398 b- defN 23-Sep-19 00:46 raydp/tf/estimator.py
--rw-r--r--  2.0 unx      853 b- defN 23-Sep-19 00:46 raydp/torch/__init__.py
--rw-r--r--  2.0 unx     1218 b- defN 23-Sep-19 00:46 raydp/torch/config.py
--rw-r--r--  2.0 unx    18693 b- defN 23-Sep-19 00:46 raydp/torch/estimator.py
--rw-r--r--  2.0 unx     2202 b- defN 23-Sep-19 00:46 raydp/torch/torch_metrics.py
--rw-r--r--  2.0 unx     3862 b- defN 23-Sep-19 00:46 raydp/torch/torch_ml_dataset.py
--rw-r--r--  2.0 unx      857 b- defN 23-Sep-19 00:46 raydp/xgboost/__init__.py
--rw-r--r--  2.0 unx     5889 b- defN 23-Sep-19 00:46 raydp/xgboost/estimator.py
--rw-r--r--  2.0 unx    10110 b- defN 23-Sep-19 00:48 raydp_nightly-2023.9.19.dev0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Sep-19 00:48 raydp_nightly-2023.9.19.dev0.dist-info/WHEEL
--rw-r--r--  2.0 unx        6 b- defN 23-Sep-19 00:48 raydp_nightly-2023.9.19.dev0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3488 b- defN 23-Sep-19 00:48 raydp_nightly-2023.9.19.dev0.dist-info/RECORD
-41 files, 556382 bytes uncompressed, 387660 bytes compressed:  30.3%
+Zip file size: 406850 bytes, number of entries: 42
+-rw-r--r--  2.0 unx      902 b- defN 24-Apr-10 00:47 raydp/__init__.py
+-rw-r--r--  2.0 unx    10438 b- defN 24-Apr-10 00:47 raydp/context.py
+-rw-r--r--  2.0 unx     1380 b- defN 24-Apr-10 00:47 raydp/estimator.py
+-rw-r--r--  2.0 unx     2764 b- defN 24-Apr-10 00:47 raydp/ray_cluster_resources.py
+-rw-r--r--  2.0 unx     3007 b- defN 24-Apr-10 00:47 raydp/services.py
+-rw-r--r--  2.0 unx     7666 b- defN 24-Apr-10 00:47 raydp/utils.py
+-rw-r--r--  2.0 unx     1474 b- defN 24-Apr-10 00:47 raydp/versions.py
+-rwxr-xr-x  2.0 unx     5101 b- defN 24-Apr-10 00:47 raydp/bin/raydp-submit
+-rw-r--r--  2.0 unx   287221 b- defN 24-Apr-10 00:48 raydp/jars/raydp-1.7.0-SNAPSHOT.jar
+-rw-r--r--  2.0 unx     7071 b- defN 24-Apr-10 00:48 raydp/jars/raydp-agent-1.7.0-SNAPSHOT.jar
+-rw-r--r--  2.0 unx    16000 b- defN 24-Apr-10 00:48 raydp/jars/raydp-shims-common-1.7.0-SNAPSHOT.jar
+-rw-r--r--  2.0 unx    14050 b- defN 24-Apr-10 00:48 raydp/jars/raydp-shims-spark322-1.7.0-SNAPSHOT.jar
+-rw-r--r--  2.0 unx    15256 b- defN 24-Apr-10 00:48 raydp/jars/raydp-shims-spark330-1.7.0-SNAPSHOT.jar
+-rw-r--r--  2.0 unx    16185 b- defN 24-Apr-10 00:48 raydp/jars/raydp-shims-spark340-1.7.0-SNAPSHOT.jar
+-rw-r--r--  2.0 unx    16005 b- defN 24-Apr-10 00:48 raydp/jars/raydp-shims-spark350-1.7.0-SNAPSHOT.jar
+-rw-r--r--  2.0 unx     4396 b- defN 24-Apr-10 00:47 raydp/mpi/__init__.py
+-rw-r--r--  2.0 unx     1122 b- defN 24-Apr-10 00:47 raydp/mpi/constants.py
+-rw-r--r--  2.0 unx    15624 b- defN 24-Apr-10 00:47 raydp/mpi/mpi_job.py
+-rw-r--r--  2.0 unx     8304 b- defN 24-Apr-10 00:47 raydp/mpi/mpi_worker.py
+-rw-r--r--  2.0 unx     4044 b- defN 24-Apr-10 00:47 raydp/mpi/utils.py
+-rw-r--r--  2.0 unx      893 b- defN 24-Apr-10 00:47 raydp/mpi/network/__init__.py
+-rw-r--r--  2.0 unx    15133 b- defN 24-Apr-10 00:47 raydp/mpi/network/network_pb2.py
+-rw-r--r--  2.0 unx     8980 b- defN 24-Apr-10 00:47 raydp/mpi/network/network_pb2_grpc.py
+-rw-r--r--  2.0 unx     1509 b- defN 24-Apr-10 00:47 raydp/spark/__init__.py
+-rw-r--r--  2.0 unx    26438 b- defN 24-Apr-10 00:47 raydp/spark/dataset.py
+-rw-r--r--  2.0 unx     1535 b- defN 24-Apr-10 00:47 raydp/spark/interfaces.py
+-rw-r--r--  2.0 unx     1141 b- defN 24-Apr-10 00:47 raydp/spark/parallel_iterator_worker.py
+-rw-r--r--  2.0 unx     9540 b- defN 24-Apr-10 00:47 raydp/spark/ray_cluster.py
+-rw-r--r--  2.0 unx     9286 b- defN 24-Apr-10 00:47 raydp/spark/ray_cluster_master.py
+-rw-r--r--  2.0 unx      847 b- defN 24-Apr-10 00:47 raydp/tf/__init__.py
+-rw-r--r--  2.0 unx    13334 b- defN 24-Apr-10 00:47 raydp/tf/estimator.py
+-rw-r--r--  2.0 unx      853 b- defN 24-Apr-10 00:47 raydp/torch/__init__.py
+-rw-r--r--  2.0 unx     1436 b- defN 24-Apr-10 00:47 raydp/torch/config.py
+-rw-r--r--  2.0 unx    18365 b- defN 24-Apr-10 00:47 raydp/torch/estimator.py
+-rw-r--r--  2.0 unx     2202 b- defN 24-Apr-10 00:47 raydp/torch/torch_metrics.py
+-rw-r--r--  2.0 unx     3862 b- defN 24-Apr-10 00:47 raydp/torch/torch_ml_dataset.py
+-rw-r--r--  2.0 unx      857 b- defN 24-Apr-10 00:47 raydp/xgboost/__init__.py
+-rw-r--r--  2.0 unx     6022 b- defN 24-Apr-10 00:47 raydp/xgboost/estimator.py
+-rw-r--r--  2.0 unx    10110 b- defN 24-Apr-10 00:48 raydp_nightly-2024.4.10.dev0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-10 00:48 raydp_nightly-2024.4.10.dev0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        6 b- defN 24-Apr-10 00:48 raydp_nightly-2024.4.10.dev0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3596 b- defN 24-Apr-10 00:48 raydp_nightly-2024.4.10.dev0.dist-info/RECORD
+42 files, 574047 bytes uncompressed, 401132 bytes compressed:  30.1%
```

## zipnote {}

```diff
@@ -36,14 +36,17 @@
 
 Filename: raydp/jars/raydp-shims-spark330-1.7.0-SNAPSHOT.jar
 Comment: 
 
 Filename: raydp/jars/raydp-shims-spark340-1.7.0-SNAPSHOT.jar
 Comment: 
 
+Filename: raydp/jars/raydp-shims-spark350-1.7.0-SNAPSHOT.jar
+Comment: 
+
 Filename: raydp/mpi/__init__.py
 Comment: 
 
 Filename: raydp/mpi/constants.py
 Comment: 
 
 Filename: raydp/mpi/mpi_job.py
@@ -105,20 +108,20 @@
 
 Filename: raydp/xgboost/__init__.py
 Comment: 
 
 Filename: raydp/xgboost/estimator.py
 Comment: 
 
-Filename: raydp_nightly-2023.9.19.dev0.dist-info/METADATA
+Filename: raydp_nightly-2024.4.10.dev0.dist-info/METADATA
 Comment: 
 
-Filename: raydp_nightly-2023.9.19.dev0.dist-info/WHEEL
+Filename: raydp_nightly-2024.4.10.dev0.dist-info/WHEEL
 Comment: 
 
-Filename: raydp_nightly-2023.9.19.dev0.dist-info/top_level.txt
+Filename: raydp_nightly-2024.4.10.dev0.dist-info/top_level.txt
 Comment: 
 
-Filename: raydp_nightly-2023.9.19.dev0.dist-info/RECORD
+Filename: raydp_nightly-2024.4.10.dev0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## raydp/bin/raydp-submit

```diff
@@ -47,15 +47,15 @@
 
 
 # set log4j versions for spark driver and executors inside ray worker
 # read from versions.py.
 log4j_config=()
 while read line; do
   log4j_config+=($line)
-done < <(python3 -c "from raydp import versions; print(versions.SPARK_LOG4J_VERSION); 
+done < <(python3 -c "import os; from raydp import versions; print(versions.SPARK_LOG4J_VERSION); 
 print(versions.SPARK_LOG4J_CONFIG_FILE_NAME_KEY);
 print(os.getenv(\"SPARK_LOG4J_CONFIG_FILE_NAME\", versions.SPARK_LOG4J_CONFIG_FILE_NAME_DEFAULT));
 print(versions.RAY_LOG4J_VERSION);
 print(versions.RAY_LOG4J_CONFIG_FILE_NAME_KEY);
 print(os.getenv(\"RAY_LOG4J_CONFIG_FILE_NAME\", versions.RAY_LOG4J_CONFIG_FILE_NAME_DEFAULT));
 ")
```

## raydp/jars/raydp-1.7.0-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,115 +1,115 @@
-Zip file size: 286937 bytes, number of entries: 113
--rw-r--r--  2.0 unx       82 b- defN 23-Sep-19 00:47 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/scheduler/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/scheduler/cluster/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/scheduler/cluster/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/util/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/rdd/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/executor/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/sql/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/sql/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/deploy/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/deploy/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/services/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/raydp/
--rw-r--r--  2.0 unx     1074 b- defN 23-Sep-19 00:47 org/apache/spark/RayDPException.class
--rw-r--r--  2.0 unx     3427 b- defN 23-Sep-19 00:47 org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$AppMasterClient$$anonfun$receive$1.class
--rw-r--r--  2.0 unx     1591 b- defN 23-Sep-19 00:47 org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$$anon$1.class
--rw-r--r--  2.0 unx    30238 b- defN 23-Sep-19 00:47 org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend.class
--rw-r--r--  2.0 unx     2657 b- defN 23-Sep-19 00:47 org/apache/spark/scheduler/cluster/raydp/RayClusterManager.class
--rw-r--r--  2.0 unx     9767 b- defN 23-Sep-19 00:47 org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$AppMasterClient.class
--rw-r--r--  2.0 unx     6753 b- defN 23-Sep-19 00:47 org/apache/spark/util/IvyProperties.class
--rw-r--r--  2.0 unx     2546 b- defN 23-Sep-19 00:47 org/apache/spark/util/IvyProperties$.class
--rw-r--r--  2.0 unx    32797 b- defN 23-Sep-19 00:47 org/apache/spark/util/DependencyUtils$.class
--rw-r--r--  2.0 unx     4058 b- defN 23-Sep-19 00:47 org/apache/spark/util/DependencyUtils.class
--rw-r--r--  2.0 unx     6313 b- defN 23-Sep-19 00:47 org/apache/spark/rdd/RayDatasetRDD.class
--rw-r--r--  2.0 unx     5710 b- defN 23-Sep-19 00:47 org/apache/spark/rdd/RayObjectRefRDD.class
--rw-r--r--  2.0 unx     1497 b- defN 23-Sep-19 00:47 org/apache/spark/rdd/RayObjectRefRDDPartition.class
--rw-r--r--  2.0 unx     1694 b- defN 23-Sep-19 00:47 org/apache/spark/rdd/RayDatasetRDDPartition.class
--rw-r--r--  2.0 unx    37703 b- defN 23-Sep-19 00:47 org/apache/spark/executor/RayDPExecutor.class
--rw-r--r--  2.0 unx     2488 b- defN 23-Sep-19 00:47 org/apache/spark/executor/RayDPExecutor$$anon$1.class
--rw-r--r--  2.0 unx     5407 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/RecordBatch.class
--rw-r--r--  2.0 unx     3948 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/ObjectStoreReader$.class
--rw-r--r--  2.0 unx     1899 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/ObjectRefHolder.class
--rw-r--r--  2.0 unx    12936 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/ObjectStoreWriter$.class
--rw-r--r--  2.0 unx    17199 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/ObjectStoreWriter.class
--rw-r--r--  2.0 unx     2074 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/ObjectStoreReader.class
--rw-r--r--  2.0 unx     1955 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/ObjectRefHolder$$anon$1.class
--rw-r--r--  2.0 unx     2158 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/RecordBatch$.class
--rw-r--r--  2.0 unx     2902 b- defN 23-Sep-19 00:47 org/apache/spark/sql/raydp/ObjectRefHolder$.class
--rw-r--r--  2.0 unx     2124 b- defN 23-Sep-19 00:47 org/apache/spark/raydp/RayDPUtils.class
--rw-r--r--  2.0 unx     1594 b- defN 23-Sep-19 00:47 org/apache/spark/raydp/SparkOnRayConfigs.class
--rw-r--r--  2.0 unx     8942 b- defN 23-Sep-19 00:47 org/apache/spark/raydp/RayExecutorUtils.class
--rw-r--r--  2.0 unx     8861 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/OptionAssigner.class
--rw-r--r--  2.0 unx     1908 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmitAction.class
--rw-r--r--  2.0 unx     2446 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate$.class
--rw-r--r--  2.0 unx      809 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/InProcessSparkSubmit.class
--rw-r--r--  2.0 unx      765 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/InProcessSparkSubmit$.class
--rw-r--r--  2.0 unx    10446 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmit$.class
--rw-r--r--  2.0 unx     1405 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmit$$anon$1.class
--rw-r--r--  2.0 unx     1781 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmit$$anon$2$$anon$3.class
--rw-r--r--  2.0 unx    74157 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmit.class
--rw-r--r--  2.0 unx      932 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmitOperation.class
--rw-r--r--  2.0 unx     2224 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmit$$anon$2.class
--rw-r--r--  2.0 unx     3441 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate.class
--rw-r--r--  2.0 unx     1011 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmitAction$.class
--rw-r--r--  2.0 unx     3800 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/OptionAssigner$.class
--rw-r--r--  2.0 unx     6905 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayDPDriverAgent$RayDPDriverAgentEndpoint.class
--rw-r--r--  2.0 unx     1220 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ApplicationState$.class
--rw-r--r--  2.0 unx     2007 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RequestAddPendingRestartedExecutor$.class
--rw-r--r--  2.0 unx     4703 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ExecutorStarted.class
--rw-r--r--  2.0 unx     4760 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/UnregisterApplication.class
--rw-r--r--  2.0 unx     8584 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/Command.class
--rw-r--r--  2.0 unx     5186 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RegisterExecutor.class
--rw-r--r--  2.0 unx     5810 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RegisterApplication.class
--rw-r--r--  2.0 unx     2594 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RegisterApplication$.class
--rw-r--r--  2.0 unx     8511 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/AppMasterJavaBridge.class
--rw-r--r--  2.0 unx    25033 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint.class
--rw-r--r--  2.0 unx    17397 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ApplicationInfo.class
--rw-r--r--  2.0 unx     3233 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/Command$.class
--rw-r--r--  2.0 unx    11138 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1.class
--rw-r--r--  2.0 unx      646 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayDPDriverAgent$.class
--rw-r--r--  2.0 unx     4506 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayDPDriverAgent$RayDPDriverAgentEndpoint$$anonfun$receiveAndReply$1.class
--rw-r--r--  2.0 unx     2091 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ApplicationState.class
--rw-r--r--  2.0 unx     4279 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayAppMaster$.class
--rw-r--r--  2.0 unx     1836 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ExecutorStarted$.class
--rw-r--r--  2.0 unx     5286 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/AddPendingRestartedExecutorReply.class
--rw-r--r--  2.0 unx     2966 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ExecutorDesc$.class
--rw-r--r--  2.0 unx     2200 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RequestExecutors$.class
--rw-r--r--  2.0 unx     2328 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RegisteredApplication$.class
--rw-r--r--  2.0 unx     5513 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RegisteredApplication.class
--rw-r--r--  2.0 unx     4037 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayExternalShuffleService$.class
--rw-r--r--  2.0 unx     4110 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ExternalShuffleServiceUtils.class
--rw-r--r--  2.0 unx     7646 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ExecutorDesc.class
--rw-r--r--  2.0 unx    13706 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayAppMaster.class
--rw-r--r--  2.0 unx     9411 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/AppMasterEntryPoint$.class
--rw-r--r--  2.0 unx     5832 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayAppMasterUtils.class
--rw-r--r--  2.0 unx     2314 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/KillExecutors$.class
--rw-r--r--  2.0 unx     6159 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayExternalShuffleService.class
--rw-r--r--  2.0 unx    11036 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ApplicationDescription.class
--rw-r--r--  2.0 unx     4904 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayDPDriverAgent.class
--rw-r--r--  2.0 unx     4944 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RequestAddPendingRestartedExecutor.class
--rw-r--r--  2.0 unx     4577 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RecacheRDD.class
--rw-r--r--  2.0 unx     1885 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/UnregisterApplication$.class
--rw-r--r--  2.0 unx     5698 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/KillExecutors.class
--rw-r--r--  2.0 unx     6842 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receive$1.class
--rw-r--r--  2.0 unx     1851 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RecacheRDD$.class
--rw-r--r--  2.0 unx     1881 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/AppMasterEntryPoint.class
--rw-r--r--  2.0 unx     2089 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RegisterExecutor$.class
--rw-r--r--  2.0 unx     2120 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/AddPendingRestartedExecutorReply$.class
--rw-r--r--  2.0 unx     5309 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RequestExecutors.class
--rw-r--r--  2.0 unx     4765 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/ApplicationDescription$.class
--rw-r--r--  2.0 unx      776 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/raydp/RayDPDeployMessage.class
--rw-r--r--  2.0 unx     7458 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmitUtils.class
--rw-r--r--  2.0 unx    37492 b- defN 23-Sep-19 00:47 org/apache/spark/deploy/SparkSubmitUtils$.class
--rw-r--r--  2.0 unx       58 b- defN 23-Sep-19 00:47 META-INF/services/org.apache.spark.scheduler.ExternalClusterManager
--rw-r--r--  2.0 unx     9974 b- defN 23-Sep-19 00:46 META-INF/maven/com.intel/raydp/pom.xml
--rw-r--r--  2.0 unx       58 b- defN 23-Sep-19 00:47 META-INF/maven/com.intel/raydp/pom.properties
-113 files, 633183 bytes uncompressed, 267199 bytes compressed:  57.8%
+Zip file size: 287221 bytes, number of entries: 113
+-rw-r--r--  2.0 unx       82 b- defN 24-Apr-10 00:48 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/scheduler/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/scheduler/cluster/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/scheduler/cluster/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/sql/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/sql/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/deploy/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/deploy/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/executor/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/util/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/rdd/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/services/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/raydp/
+-rw-r--r--  2.0 unx     1591 b- defN 24-Apr-10 00:48 org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$$anon$1.class
+-rw-r--r--  2.0 unx     2657 b- defN 24-Apr-10 00:48 org/apache/spark/scheduler/cluster/raydp/RayClusterManager.class
+-rw-r--r--  2.0 unx    30238 b- defN 24-Apr-10 00:48 org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend.class
+-rw-r--r--  2.0 unx     3427 b- defN 24-Apr-10 00:48 org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$AppMasterClient$$anonfun$receive$1.class
+-rw-r--r--  2.0 unx     9767 b- defN 24-Apr-10 00:48 org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$AppMasterClient.class
+-rw-r--r--  2.0 unx     2158 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/RecordBatch$.class
+-rw-r--r--  2.0 unx     5407 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/RecordBatch.class
+-rw-r--r--  2.0 unx     3948 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/ObjectStoreReader$.class
+-rw-r--r--  2.0 unx    17199 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/ObjectStoreWriter.class
+-rw-r--r--  2.0 unx     2902 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/ObjectRefHolder$.class
+-rw-r--r--  2.0 unx    12936 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/ObjectStoreWriter$.class
+-rw-r--r--  2.0 unx     1955 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/ObjectRefHolder$$anon$1.class
+-rw-r--r--  2.0 unx     1899 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/ObjectRefHolder.class
+-rw-r--r--  2.0 unx     2074 b- defN 24-Apr-10 00:48 org/apache/spark/sql/raydp/ObjectStoreReader.class
+-rw-r--r--  2.0 unx    74157 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmit.class
+-rw-r--r--  2.0 unx     1405 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmit$$anon$1.class
+-rw-r--r--  2.0 unx     1781 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmit$$anon$2$$anon$3.class
+-rw-r--r--  2.0 unx    10446 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmit$.class
+-rw-r--r--  2.0 unx      809 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/InProcessSparkSubmit.class
+-rw-r--r--  2.0 unx     1220 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ApplicationState$.class
+-rw-r--r--  2.0 unx     1885 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/UnregisterApplication$.class
+-rw-r--r--  2.0 unx     3233 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/Command$.class
+-rw-r--r--  2.0 unx    25456 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint.class
+-rw-r--r--  2.0 unx     4577 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RecacheRDD.class
+-rw-r--r--  2.0 unx     4944 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RequestAddPendingRestartedExecutor.class
+-rw-r--r--  2.0 unx     5513 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RegisteredApplication.class
+-rw-r--r--  2.0 unx     1881 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/AppMasterEntryPoint.class
+-rw-r--r--  2.0 unx     8511 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/AppMasterJavaBridge.class
+-rw-r--r--  2.0 unx     2594 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RegisterApplication$.class
+-rw-r--r--  2.0 unx     4765 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ApplicationDescription$.class
+-rw-r--r--  2.0 unx     1836 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ExecutorStarted$.class
+-rw-r--r--  2.0 unx    11036 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ApplicationDescription.class
+-rw-r--r--  2.0 unx     2328 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RegisteredApplication$.class
+-rw-r--r--  2.0 unx     4279 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayAppMaster$.class
+-rw-r--r--  2.0 unx     6842 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receive$1.class
+-rw-r--r--  2.0 unx     4904 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayDPDriverAgent.class
+-rw-r--r--  2.0 unx     8584 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/Command.class
+-rw-r--r--  2.0 unx     2089 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RegisterExecutor$.class
+-rw-r--r--  2.0 unx     1851 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RecacheRDD$.class
+-rw-r--r--  2.0 unx     5309 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RequestExecutors.class
+-rw-r--r--  2.0 unx    17522 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ApplicationInfo.class
+-rw-r--r--  2.0 unx      776 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayDPDeployMessage.class
+-rw-r--r--  2.0 unx     4760 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/UnregisterApplication.class
+-rw-r--r--  2.0 unx     5698 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/KillExecutors.class
+-rw-r--r--  2.0 unx     5286 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/AddPendingRestartedExecutorReply.class
+-rw-r--r--  2.0 unx     2966 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ExecutorDesc$.class
+-rw-r--r--  2.0 unx     2314 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/KillExecutors$.class
+-rw-r--r--  2.0 unx     5810 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RegisterApplication.class
+-rw-r--r--  2.0 unx     7646 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ExecutorDesc.class
+-rw-r--r--  2.0 unx     6905 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayDPDriverAgent$RayDPDriverAgentEndpoint.class
+-rw-r--r--  2.0 unx     5832 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayAppMasterUtils.class
+-rw-r--r--  2.0 unx     9411 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/AppMasterEntryPoint$.class
+-rw-r--r--  2.0 unx     4037 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayExternalShuffleService$.class
+-rw-r--r--  2.0 unx    11139 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1.class
+-rw-r--r--  2.0 unx     2007 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RequestAddPendingRestartedExecutor$.class
+-rw-r--r--  2.0 unx      646 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayDPDriverAgent$.class
+-rw-r--r--  2.0 unx     4703 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ExecutorStarted.class
+-rw-r--r--  2.0 unx     2120 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/AddPendingRestartedExecutorReply$.class
+-rw-r--r--  2.0 unx     5186 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RegisterExecutor.class
+-rw-r--r--  2.0 unx     4506 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayDPDriverAgent$RayDPDriverAgentEndpoint$$anonfun$receiveAndReply$1.class
+-rw-r--r--  2.0 unx     2091 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ApplicationState.class
+-rw-r--r--  2.0 unx     2200 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RequestExecutors$.class
+-rw-r--r--  2.0 unx     6159 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayExternalShuffleService.class
+-rw-r--r--  2.0 unx    13706 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/RayAppMaster.class
+-rw-r--r--  2.0 unx     4110 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/raydp/ExternalShuffleServiceUtils.class
+-rw-r--r--  2.0 unx     1011 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmitAction$.class
+-rw-r--r--  2.0 unx     3441 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate.class
+-rw-r--r--  2.0 unx     1908 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmitAction.class
+-rw-r--r--  2.0 unx     2446 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate$.class
+-rw-r--r--  2.0 unx    37492 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmitUtils$.class
+-rw-r--r--  2.0 unx     8861 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/OptionAssigner.class
+-rw-r--r--  2.0 unx      765 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/InProcessSparkSubmit$.class
+-rw-r--r--  2.0 unx     3800 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/OptionAssigner$.class
+-rw-r--r--  2.0 unx     2224 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmit$$anon$2.class
+-rw-r--r--  2.0 unx      932 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmitOperation.class
+-rw-r--r--  2.0 unx     7458 b- defN 24-Apr-10 00:48 org/apache/spark/deploy/SparkSubmitUtils.class
+-rw-r--r--  2.0 unx     2124 b- defN 24-Apr-10 00:48 org/apache/spark/raydp/RayDPUtils.class
+-rw-r--r--  2.0 unx     1594 b- defN 24-Apr-10 00:48 org/apache/spark/raydp/SparkOnRayConfigs.class
+-rw-r--r--  2.0 unx     8942 b- defN 24-Apr-10 00:48 org/apache/spark/raydp/RayExecutorUtils.class
+-rw-r--r--  2.0 unx     2488 b- defN 24-Apr-10 00:48 org/apache/spark/executor/RayDPExecutor$$anon$1.class
+-rw-r--r--  2.0 unx    37703 b- defN 24-Apr-10 00:48 org/apache/spark/executor/RayDPExecutor.class
+-rw-r--r--  2.0 unx     2546 b- defN 24-Apr-10 00:48 org/apache/spark/util/IvyProperties$.class
+-rw-r--r--  2.0 unx     6753 b- defN 24-Apr-10 00:48 org/apache/spark/util/IvyProperties.class
+-rw-r--r--  2.0 unx     4058 b- defN 24-Apr-10 00:48 org/apache/spark/util/DependencyUtils.class
+-rw-r--r--  2.0 unx    32797 b- defN 24-Apr-10 00:48 org/apache/spark/util/DependencyUtils$.class
+-rw-r--r--  2.0 unx     1074 b- defN 24-Apr-10 00:48 org/apache/spark/RayDPException.class
+-rw-r--r--  2.0 unx     5710 b- defN 24-Apr-10 00:48 org/apache/spark/rdd/RayObjectRefRDD.class
+-rw-r--r--  2.0 unx     6313 b- defN 24-Apr-10 00:48 org/apache/spark/rdd/RayDatasetRDD.class
+-rw-r--r--  2.0 unx     1694 b- defN 24-Apr-10 00:48 org/apache/spark/rdd/RayDatasetRDDPartition.class
+-rw-r--r--  2.0 unx     1497 b- defN 24-Apr-10 00:48 org/apache/spark/rdd/RayObjectRefRDDPartition.class
+-rw-r--r--  2.0 unx       58 b- defN 24-Apr-10 00:48 META-INF/services/org.apache.spark.scheduler.ExternalClusterManager
+-rw-r--r--  2.0 unx     9974 b- defN 24-Apr-10 00:47 META-INF/maven/com.intel/raydp/pom.xml
+-rw-r--r--  2.0 unx       58 b- defN 24-Apr-10 00:48 META-INF/maven/com.intel/raydp/pom.properties
+113 files, 633732 bytes uncompressed, 267483 bytes compressed:  57.8%
```

### zipnote «TEMP»/diffoscope_1d0ljn3y_/tmphlpjxnzw_.zip

```diff
@@ -18,318 +18,318 @@
 
 Filename: org/apache/spark/scheduler/cluster/
 Comment: 
 
 Filename: org/apache/spark/scheduler/cluster/raydp/
 Comment: 
 
-Filename: org/apache/spark/util/
+Filename: org/apache/spark/sql/
 Comment: 
 
-Filename: org/apache/spark/rdd/
+Filename: org/apache/spark/sql/raydp/
 Comment: 
 
-Filename: org/apache/spark/executor/
+Filename: org/apache/spark/deploy/
 Comment: 
 
-Filename: org/apache/spark/sql/
+Filename: org/apache/spark/deploy/raydp/
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/
+Filename: org/apache/spark/raydp/
 Comment: 
 
-Filename: org/apache/spark/raydp/
+Filename: org/apache/spark/executor/
 Comment: 
 
-Filename: org/apache/spark/deploy/
+Filename: org/apache/spark/util/
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/
+Filename: org/apache/spark/rdd/
 Comment: 
 
 Filename: META-INF/services/
 Comment: 
 
 Filename: META-INF/maven/
 Comment: 
 
 Filename: META-INF/maven/com.intel/
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp/
 Comment: 
 
-Filename: org/apache/spark/RayDPException.class
-Comment: 
-
-Filename: org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$AppMasterClient$$anonfun$receive$1.class
+Filename: org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$$anon$1.class
 Comment: 
 
-Filename: org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$$anon$1.class
+Filename: org/apache/spark/scheduler/cluster/raydp/RayClusterManager.class
 Comment: 
 
 Filename: org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend.class
 Comment: 
 
-Filename: org/apache/spark/scheduler/cluster/raydp/RayClusterManager.class
+Filename: org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$AppMasterClient$$anonfun$receive$1.class
 Comment: 
 
 Filename: org/apache/spark/scheduler/cluster/raydp/RayCoarseGrainedSchedulerBackend$AppMasterClient.class
 Comment: 
 
-Filename: org/apache/spark/util/IvyProperties.class
-Comment: 
-
-Filename: org/apache/spark/util/IvyProperties$.class
+Filename: org/apache/spark/sql/raydp/RecordBatch$.class
 Comment: 
 
-Filename: org/apache/spark/util/DependencyUtils$.class
+Filename: org/apache/spark/sql/raydp/RecordBatch.class
 Comment: 
 
-Filename: org/apache/spark/util/DependencyUtils.class
+Filename: org/apache/spark/sql/raydp/ObjectStoreReader$.class
 Comment: 
 
-Filename: org/apache/spark/rdd/RayDatasetRDD.class
+Filename: org/apache/spark/sql/raydp/ObjectStoreWriter.class
 Comment: 
 
-Filename: org/apache/spark/rdd/RayObjectRefRDD.class
+Filename: org/apache/spark/sql/raydp/ObjectRefHolder$.class
 Comment: 
 
-Filename: org/apache/spark/rdd/RayObjectRefRDDPartition.class
+Filename: org/apache/spark/sql/raydp/ObjectStoreWriter$.class
 Comment: 
 
-Filename: org/apache/spark/rdd/RayDatasetRDDPartition.class
+Filename: org/apache/spark/sql/raydp/ObjectRefHolder$$anon$1.class
 Comment: 
 
-Filename: org/apache/spark/executor/RayDPExecutor.class
+Filename: org/apache/spark/sql/raydp/ObjectRefHolder.class
 Comment: 
 
-Filename: org/apache/spark/executor/RayDPExecutor$$anon$1.class
+Filename: org/apache/spark/sql/raydp/ObjectStoreReader.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/RecordBatch.class
+Filename: org/apache/spark/deploy/SparkSubmit.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/ObjectStoreReader$.class
+Filename: org/apache/spark/deploy/SparkSubmit$$anon$1.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/ObjectRefHolder.class
+Filename: org/apache/spark/deploy/SparkSubmit$$anon$2$$anon$3.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/ObjectStoreWriter$.class
+Filename: org/apache/spark/deploy/SparkSubmit$.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/ObjectStoreWriter.class
+Filename: org/apache/spark/deploy/InProcessSparkSubmit.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/ObjectStoreReader.class
+Filename: org/apache/spark/deploy/raydp/ApplicationState$.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/ObjectRefHolder$$anon$1.class
+Filename: org/apache/spark/deploy/raydp/UnregisterApplication$.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/RecordBatch$.class
+Filename: org/apache/spark/deploy/raydp/Command$.class
 Comment: 
 
-Filename: org/apache/spark/sql/raydp/ObjectRefHolder$.class
+Filename: org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint.class
 Comment: 
 
-Filename: org/apache/spark/raydp/RayDPUtils.class
+Filename: org/apache/spark/deploy/raydp/RecacheRDD.class
 Comment: 
 
-Filename: org/apache/spark/raydp/SparkOnRayConfigs.class
+Filename: org/apache/spark/deploy/raydp/RequestAddPendingRestartedExecutor.class
 Comment: 
 
-Filename: org/apache/spark/raydp/RayExecutorUtils.class
+Filename: org/apache/spark/deploy/raydp/RegisteredApplication.class
 Comment: 
 
-Filename: org/apache/spark/deploy/OptionAssigner.class
+Filename: org/apache/spark/deploy/raydp/AppMasterEntryPoint.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmitAction.class
+Filename: org/apache/spark/deploy/raydp/AppMasterJavaBridge.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate$.class
+Filename: org/apache/spark/deploy/raydp/RegisterApplication$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/InProcessSparkSubmit.class
+Filename: org/apache/spark/deploy/raydp/ApplicationDescription$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/InProcessSparkSubmit$.class
+Filename: org/apache/spark/deploy/raydp/ExecutorStarted$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmit$.class
+Filename: org/apache/spark/deploy/raydp/ApplicationDescription.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmit$$anon$1.class
+Filename: org/apache/spark/deploy/raydp/RegisteredApplication$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmit$$anon$2$$anon$3.class
+Filename: org/apache/spark/deploy/raydp/RayAppMaster$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmit.class
+Filename: org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receive$1.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmitOperation.class
+Filename: org/apache/spark/deploy/raydp/RayDPDriverAgent.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmit$$anon$2.class
+Filename: org/apache/spark/deploy/raydp/Command.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate.class
+Filename: org/apache/spark/deploy/raydp/RegisterExecutor$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmitAction$.class
+Filename: org/apache/spark/deploy/raydp/RecacheRDD$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/OptionAssigner$.class
+Filename: org/apache/spark/deploy/raydp/RequestExecutors.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayDPDriverAgent$RayDPDriverAgentEndpoint.class
+Filename: org/apache/spark/deploy/raydp/ApplicationInfo.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ApplicationState$.class
+Filename: org/apache/spark/deploy/raydp/RayDPDeployMessage.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RequestAddPendingRestartedExecutor$.class
+Filename: org/apache/spark/deploy/raydp/UnregisterApplication.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ExecutorStarted.class
+Filename: org/apache/spark/deploy/raydp/KillExecutors.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/UnregisterApplication.class
+Filename: org/apache/spark/deploy/raydp/AddPendingRestartedExecutorReply.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/Command.class
+Filename: org/apache/spark/deploy/raydp/ExecutorDesc$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RegisterExecutor.class
+Filename: org/apache/spark/deploy/raydp/KillExecutors$.class
 Comment: 
 
 Filename: org/apache/spark/deploy/raydp/RegisterApplication.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RegisterApplication$.class
+Filename: org/apache/spark/deploy/raydp/ExecutorDesc.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/AppMasterJavaBridge.class
+Filename: org/apache/spark/deploy/raydp/RayDPDriverAgent$RayDPDriverAgentEndpoint.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint.class
+Filename: org/apache/spark/deploy/raydp/RayAppMasterUtils.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ApplicationInfo.class
+Filename: org/apache/spark/deploy/raydp/AppMasterEntryPoint$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/Command$.class
+Filename: org/apache/spark/deploy/raydp/RayExternalShuffleService$.class
 Comment: 
 
 Filename: org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayDPDriverAgent$.class
+Filename: org/apache/spark/deploy/raydp/RequestAddPendingRestartedExecutor$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayDPDriverAgent$RayDPDriverAgentEndpoint$$anonfun$receiveAndReply$1.class
+Filename: org/apache/spark/deploy/raydp/RayDPDriverAgent$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ApplicationState.class
+Filename: org/apache/spark/deploy/raydp/ExecutorStarted.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayAppMaster$.class
+Filename: org/apache/spark/deploy/raydp/AddPendingRestartedExecutorReply$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ExecutorStarted$.class
+Filename: org/apache/spark/deploy/raydp/RegisterExecutor.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/AddPendingRestartedExecutorReply.class
+Filename: org/apache/spark/deploy/raydp/RayDPDriverAgent$RayDPDriverAgentEndpoint$$anonfun$receiveAndReply$1.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ExecutorDesc$.class
+Filename: org/apache/spark/deploy/raydp/ApplicationState.class
 Comment: 
 
 Filename: org/apache/spark/deploy/raydp/RequestExecutors$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RegisteredApplication$.class
+Filename: org/apache/spark/deploy/raydp/RayExternalShuffleService.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RegisteredApplication.class
+Filename: org/apache/spark/deploy/raydp/RayAppMaster.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayExternalShuffleService$.class
+Filename: org/apache/spark/deploy/raydp/ExternalShuffleServiceUtils.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ExternalShuffleServiceUtils.class
+Filename: org/apache/spark/deploy/SparkSubmitAction$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ExecutorDesc.class
+Filename: org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayAppMaster.class
+Filename: org/apache/spark/deploy/SparkSubmitAction.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/AppMasterEntryPoint$.class
+Filename: org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayAppMasterUtils.class
+Filename: org/apache/spark/deploy/SparkSubmitUtils$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/KillExecutors$.class
+Filename: org/apache/spark/deploy/OptionAssigner.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayExternalShuffleService.class
+Filename: org/apache/spark/deploy/InProcessSparkSubmit$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ApplicationDescription.class
+Filename: org/apache/spark/deploy/OptionAssigner$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayDPDriverAgent.class
+Filename: org/apache/spark/deploy/SparkSubmit$$anon$2.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RequestAddPendingRestartedExecutor.class
+Filename: org/apache/spark/deploy/SparkSubmitOperation.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RecacheRDD.class
+Filename: org/apache/spark/deploy/SparkSubmitUtils.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/UnregisterApplication$.class
+Filename: org/apache/spark/raydp/RayDPUtils.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/KillExecutors.class
+Filename: org/apache/spark/raydp/SparkOnRayConfigs.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receive$1.class
+Filename: org/apache/spark/raydp/RayExecutorUtils.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RecacheRDD$.class
+Filename: org/apache/spark/executor/RayDPExecutor$$anon$1.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/AppMasterEntryPoint.class
+Filename: org/apache/spark/executor/RayDPExecutor.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RegisterExecutor$.class
+Filename: org/apache/spark/util/IvyProperties$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/AddPendingRestartedExecutorReply$.class
+Filename: org/apache/spark/util/IvyProperties.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RequestExecutors.class
+Filename: org/apache/spark/util/DependencyUtils.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/ApplicationDescription$.class
+Filename: org/apache/spark/util/DependencyUtils$.class
 Comment: 
 
-Filename: org/apache/spark/deploy/raydp/RayDPDeployMessage.class
+Filename: org/apache/spark/RayDPException.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmitUtils.class
+Filename: org/apache/spark/rdd/RayObjectRefRDD.class
 Comment: 
 
-Filename: org/apache/spark/deploy/SparkSubmitUtils$.class
+Filename: org/apache/spark/rdd/RayDatasetRDD.class
+Comment: 
+
+Filename: org/apache/spark/rdd/RayDatasetRDDPartition.class
+Comment: 
+
+Filename: org/apache/spark/rdd/RayObjectRefRDDPartition.class
 Comment: 
 
 Filename: META-INF/services/org.apache.spark.scheduler.ExternalClusterManager
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp/pom.xml
 Comment:
```

### org/apache/spark/raydp/RayExecutorUtils.class

#### procyon -ec {}

```diff
@@ -28,16 +28,16 @@
         creator.setResource("memory", Double.valueOf(toMemoryUnits(memoryInMB)));
         for (final Map.Entry<String, Double> entry : resources.entrySet()) {
             creator.setResource((String)entry.getKey(), Double.valueOf(entry.getValue()));
         }
         if (placementGroup != null) {
             creator.setPlacementGroup(placementGroup, bundleIndex);
         }
-        creator.setMaxRestarts(3);
-        creator.setMaxTaskRetries(3);
+        creator.setMaxRestarts(-1);
+        creator.setMaxTaskRetries(-1);
         creator.setMaxConcurrency(2);
         return (ActorHandle<RayDPExecutor>)creator.remote();
     }
     
     public static void setUpExecutor(final ActorHandle<RayDPExecutor> handler, final String appId, final String driverUrl, final int cores, final String classPathEntries) {
         handler.task(RayDPExecutor::startUp, (Object)appId, (Object)driverUrl, (Object)Integer.valueOf(cores), (Object)classPathEntries).remote();
     }
```

### org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint.class

#### procyon -ec {}

```diff
@@ -233,15 +233,15 @@
     }
     
     public PartialFunction<Object, BoxedUnit> receiveAndReply(final RpcCallContext context) {
         return (PartialFunction<Object, BoxedUnit>)new RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply.RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1(this, context);
     }
     
     public void onDisconnected(final RpcAddress remoteAddress) {
-        this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().kill(remoteAddress);
+        this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().kill(remoteAddress, false);
     }
     
     public void onStop() {
         if (this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$nodesWithShuffleService() != null) {
             this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$nodesWithShuffleService().values().foreach(RayAppMasterEndpoint::$anonfun$onStop$1$adapted);
             this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$nodesWithShuffleService_$eq((HashMap)null);
         }
@@ -287,14 +287,21 @@
     
     public void org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$requestNewExecutor() {
         final int sparkCoresPerExecutor = BoxesRunTime.unboxToInt(this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().desc().coresPerExecutor().getOrElse((Function0)RayAppMasterEndpoint::$anonfun$requestNewExecutor$1));
         final double rayActorCPU = this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().desc().rayActorCPU();
         final int memory = this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().desc().memoryPerExecutorMB();
         final String executorId = String.valueOf(BoxesRunTime.boxToInteger(this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().getNextExecutorId()));
         this.logInfo(RayAppMasterEndpoint::$anonfun$requestNewExecutor$2);
+        final boolean dynamicAllocationEnabled = this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$$outer().org$apache$spark$deploy$raydp$RayAppMaster$$conf().getBoolean("spark.dynamicAllocation.enabled", false);
+        if (dynamicAllocationEnabled) {
+            final int maxExecutor = this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$$outer().org$apache$spark$deploy$raydp$RayAppMaster$$conf().getInt("spark.dynamicAllocation.maxExecutors", 0);
+            if (this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$$outer().org$apache$spark$deploy$raydp$RayAppMaster$$restartedExecutors().size() >= maxExecutor) {
+                return;
+            }
+        }
         final ActorHandle handler = RayExecutorUtils.createExecutorActor(executorId, this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$$outer().getAppMasterEndpointUrl(), rayActorCPU, memory, (Map)JavaConverters$.MODULE$.mapAsJavaMapConverter((scala.collection.Map)this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().desc().resourceReqsPerExecutor().map(RayAppMasterEndpoint::$anonfun$requestNewExecutor$4, Map$.MODULE$.canBuildFrom())).asJava(), this.placementGroup(), this.getNextBundleIndex(), JavaConverters$.MODULE$.seqAsJavaList(this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().desc().command().javaOpts()));
         this.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo().addPendingRegisterExecutor(executorId, handler, sparkCoresPerExecutor, memory);
     }
     
     public Seq<String> org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appendActorClasspath(final Seq<String> javaOpts) {
         boolean user_set_cp;
         int i;
```

### org/apache/spark/deploy/raydp/ApplicationInfo.class

#### procyon -ec {}

```diff
@@ -20,15 +20,15 @@
 import scala.collection.mutable.HashMap;
 import scala.Enumeration;
 import org.apache.spark.rpc.RpcEndpointRef;
 import java.util.Date;
 import scala.reflect.ScalaSignature;
 import org.apache.spark.internal.Logging;
 
-@ScalaSignature(bytes = "\u0006\u0001\t%c!\u0002\u001e<\u0001}*\u0005\u0002\u0003*\u0001\u0005\u000b\u0007I\u0011\u0001+\t\u0011a\u0003!\u0011!Q\u0001\nUC\u0001\"\u0017\u0001\u0003\u0006\u0004%\tA\u0017\u0005\tM\u0002\u0011\t\u0011)A\u00057\"Aq\r\u0001BC\u0002\u0013\u0005\u0001\u000e\u0003\u0005n\u0001\t\u0005\t\u0015!\u0003j\u0011!q\u0007A!b\u0001\n\u0003y\u0007\u0002\u0003=\u0001\u0005\u0003\u0005\u000b\u0011\u00029\t\u0011e\u0004!Q1A\u0005\u0002iD\u0011\"a\u0001\u0001\u0005\u0003\u0005\u000b\u0011B>\t\u000f\u0005\u0015\u0001\u0001\"\u0001\u0002\b!Y\u0011Q\u0003\u0001A\u0002\u0003\u0007I\u0011AA\f\u0011-\tI\u0003\u0001a\u0001\u0002\u0004%\t!a\u000b\t\u0017\u0005]\u0002\u00011A\u0001B\u0003&\u0011\u0011\u0004\u0005\f\u0003s\u0001\u0001\u0019!a\u0001\n\u0003\tY\u0004C\u0006\u0002T\u0001\u0001\r\u00111A\u0005\u0002\u0005U\u0003bCA-\u0001\u0001\u0007\t\u0011)Q\u0005\u0003{A1\"a\u0017\u0001\u0001\u0004\u0005\r\u0011\"\u0001\u0002^!Y\u0011q\r\u0001A\u0002\u0003\u0007I\u0011AA5\u0011-\ti\u0007\u0001a\u0001\u0002\u0003\u0006K!a\u0018\t\u0017\u0005=\u0004\u00011AA\u0002\u0013\u0005\u0011\u0011\u000f\u0005\f\u0003+\u0003\u0001\u0019!a\u0001\n\u0003\t9\nC\u0006\u0002\u001c\u0002\u0001\r\u0011!Q!\n\u0005M\u0004bCAO\u0001\u0001\u0007\t\u0019!C\u0001\u0003?C1\"a*\u0001\u0001\u0004\u0005\r\u0011\"\u0001\u0002*\"Y\u0011Q\u0016\u0001A\u0002\u0003\u0005\u000b\u0015BAQ\u0011-\ty\u000b\u0001a\u0001\u0002\u0004%\t!!-\t\u0017\u0005e\u0006\u00011AA\u0002\u0013\u0005\u00111\u0018\u0005\f\u0003\u007f\u0003\u0001\u0019!A!B\u0013\t\u0019\f\u0003\u0006\u0002B\u0002\u0001\r\u00111A\u0005\u0002QC1\"a1\u0001\u0001\u0004\u0005\r\u0011\"\u0001\u0002F\"Q\u0011\u0011\u001a\u0001A\u0002\u0003\u0005\u000b\u0015B+\t\u0017\u0005-\u0007\u00011AA\u0002\u0013%\u0011\u0011\u0017\u0005\f\u0003\u001b\u0004\u0001\u0019!a\u0001\n\u0013\ty\rC\u0006\u0002T\u0002\u0001\r\u0011!Q!\n\u0005M\u0006\"CAk\u0001\u0001\u0007I\u0011BAY\u0011%\t9\u000e\u0001a\u0001\n\u0013\tI\u000e\u0003\u0005\u0002^\u0002\u0001\u000b\u0015BAZ\u0011\u001d\ty\u000e\u0001C\u0005\u0003CDq!a9\u0001\t\u0003\t)\u000fC\u0004\u0002x\u0002!\t!!?\t\u000f\t\r\u0001\u0001\"\u0001\u0003\u0006!9!Q\u0002\u0001\u0005\u0002\t=\u0001b\u0002B\u0007\u0001\u0011\u0005!1\u0003\u0005\b\u0005/\u0001A\u0011\u0001B\r\u0011\u001d\u0011\u0019\u0003\u0001C\u0001\u0005KAqAa\n\u0001\t\u0003\u0011)\u0003C\u0004\u0003*\u0001!\tA!\n\t\u0013\t-\u0002\u00011A\u0005\n\u0005E\u0006\"\u0003B\u0017\u0001\u0001\u0007I\u0011\u0002B\u0018\u0011!\u0011\u0019\u0004\u0001Q!\n\u0005M\u0006b\u0002B\u001b\u0001\u0011\u0005\u0011\u0011\u0017\u0005\b\u0005o\u0001A\u0011\u0001B\u0013\u0011\u001d\u0011I\u0004\u0001C\u0001\u0003CDqAa\u000f\u0001\t\u0003\u0011i\u0004C\u0004\u0003D\u0001!\tA!\u0012\t\r\t\u001d\u0003\u0001\"\u0001U\u0005=\t\u0005\u000f\u001d7jG\u0006$\u0018n\u001c8J]\u001a|'B\u0001\u001f>\u0003\u0015\u0011\u0018-\u001f3q\u0015\tqt(\u0001\u0004eKBdw.\u001f\u0006\u0003\u0001\u0006\u000bQa\u001d9be.T!AQ\"\u0002\r\u0005\u0004\u0018m\u00195f\u0015\u0005!\u0015aA8sON\u0019\u0001A\u0012'\u0011\u0005\u001dSU\"\u0001%\u000b\u0003%\u000bQa]2bY\u0006L!a\u0013%\u0003\r\u0005s\u0017PU3g!\ti\u0005+D\u0001O\u0015\tyu(\u0001\u0005j]R,'O\\1m\u0013\t\tfJA\u0004M_\u001e<\u0017N\\4\u0002\u0013M$\u0018M\u001d;US6,7\u0001A\u000b\u0002+B\u0011qIV\u0005\u0003/\"\u0013A\u0001T8oO\u0006Q1\u000f^1siRKW.\u001a\u0011\u0002\u0005%$W#A.\u0011\u0005q\u001bgBA/b!\tq\u0006*D\u0001`\u0015\t\u00017+\u0001\u0004=e>|GOP\u0005\u0003E\"\u000ba\u0001\u0015:fI\u00164\u0017B\u00013f\u0005\u0019\u0019FO]5oO*\u0011!\rS\u0001\u0004S\u0012\u0004\u0013\u0001\u00023fg\u000e,\u0012!\u001b\t\u0003U.l\u0011aO\u0005\u0003Yn\u0012a#\u00119qY&\u001c\u0017\r^5p]\u0012+7o\u0019:jaRLwN\\\u0001\u0006I\u0016\u001c8\rI\u0001\u000bgV\u0014W.\u001b;ECR,W#\u00019\u0011\u0005E4X\"\u0001:\u000b\u0005M$\u0018\u0001B;uS2T\u0011!^\u0001\u0005U\u00064\u0018-\u0003\u0002xe\n!A)\u0019;f\u0003-\u0019XOY7ji\u0012\u000bG/\u001a\u0011\u0002\r\u0011\u0014\u0018N^3s+\u0005Y\bC\u0001?\u0000\u001b\u0005i(B\u0001@@\u0003\r\u0011\boY\u0005\u0004\u0003\u0003i(A\u0004*qG\u0016sG\r]8j]R\u0014VMZ\u0001\bIJLg/\u001a:!\u0003\u0019a\u0014N\\5u}Qa\u0011\u0011BA\u0006\u0003\u001b\ty!!\u0005\u0002\u0014A\u0011!\u000e\u0001\u0005\u0006%.\u0001\r!\u0016\u0005\u00063.\u0001\ra\u0017\u0005\u0006O.\u0001\r!\u001b\u0005\u0006].\u0001\r\u0001\u001d\u0005\u0006s.\u0001\ra_\u0001\u0006gR\fG/Z\u000b\u0003\u00033\u0001B!a\u0007\u0002\"9\u0019!.!\b\n\u0007\u0005}1(\u0001\tBaBd\u0017nY1uS>t7\u000b^1uK&!\u00111EA\u0013\u0005\u00151\u0016\r\\;f\u0013\r\t9\u0003\u0013\u0002\f\u000b:,X.\u001a:bi&|g.A\u0005ti\u0006$Xm\u0018\u0013fcR!\u0011QFA\u001a!\r9\u0015qF\u0005\u0004\u0003cA%\u0001B+oSRD\u0011\"!\u000e\u000e\u0003\u0003\u0005\r!!\u0007\u0002\u0007a$\u0013'\u0001\u0004ti\u0006$X\rI\u0001\nKb,7-\u001e;peN,\"!!\u0010\u0011\u000f\u0005}\u0012\u0011J.\u0002N5\u0011\u0011\u0011\t\u0006\u0005\u0003\u0007\n)%A\u0004nkR\f'\r\\3\u000b\u0007\u0005\u001d\u0003*\u0001\u0006d_2dWm\u0019;j_:LA!a\u0013\u0002B\t9\u0001*Y:i\u001b\u0006\u0004\bc\u00016\u0002P%\u0019\u0011\u0011K\u001e\u0003\u0019\u0015CXmY;u_J$Um]2\u0002\u001b\u0015DXmY;u_J\u001cx\fJ3r)\u0011\ti#a\u0016\t\u0013\u0005U\u0002#!AA\u0002\u0005u\u0012AC3yK\u000e,Ho\u001c:tA\u0005\u0019\u0012\r\u001a3sKN\u001cHk\\#yK\u000e,Ho\u001c:JIV\u0011\u0011q\f\t\b\u0003\u007f\tI%!\u0019\\!\ra\u00181M\u0005\u0004\u0003Kj(A\u0003*qG\u0006#GM]3tg\u00069\u0012\r\u001a3sKN\u001cHk\\#yK\u000e,Ho\u001c:JI~#S-\u001d\u000b\u0005\u0003[\tY\u0007C\u0005\u00026M\t\t\u00111\u0001\u0002`\u0005!\u0012\r\u001a3sKN\u001cHk\\#yK\u000e,Ho\u001c:JI\u0002\n1#\u001a=fGV$xN]%e)>D\u0015M\u001c3mKJ,\"!a\u001d\u0011\u000f\u0005}\u0012\u0011J.\u0002vA1\u0011qOAC\u0003\u0013k!!!\u001f\u000b\t\u0005m\u0014QP\u0001\u0004CBL'\u0002BA@\u0003\u0003\u000b1A]1z\u0015\t\t\u0019)\u0001\u0002j_&!\u0011qQA=\u0005-\t5\r^8s\u0011\u0006tG\r\\3\u0011\t\u0005-\u0015\u0011S\u0007\u0003\u0003\u001bS1!a$@\u0003!)\u00070Z2vi>\u0014\u0018\u0002BAJ\u0003\u001b\u0013QBU1z\tB+\u00050Z2vi>\u0014\u0018aF3yK\u000e,Ho\u001c:JIR{\u0007*\u00198eY\u0016\u0014x\fJ3r)\u0011\ti#!'\t\u0013\u0005Ub#!AA\u0002\u0005M\u0014\u0001F3yK\u000e,Ho\u001c:JIR{\u0007*\u00198eY\u0016\u0014\b%\u0001\tsK6|g/\u001a3Fq\u0016\u001cW\u000f^8sgV\u0011\u0011\u0011\u0015\t\u0007\u0003\u007f\t\u0019+!\u0014\n\t\u0005\u0015\u0016\u0011\t\u0002\f\u0003J\u0014\u0018-\u001f\"vM\u001a,'/\u0001\u000bsK6|g/\u001a3Fq\u0016\u001cW\u000f^8sg~#S-\u001d\u000b\u0005\u0003[\tY\u000bC\u0005\u00026e\t\t\u00111\u0001\u0002\"\u0006\t\"/Z7pm\u0016$W\t_3dkR|'o\u001d\u0011\u0002\u0019\r|'/Z:He\u0006tG/\u001a3\u0016\u0005\u0005M\u0006cA$\u00026&\u0019\u0011q\u0017%\u0003\u0007%sG/\u0001\td_J,7o\u0012:b]R,Gm\u0018\u0013fcR!\u0011QFA_\u0011%\t)\u0004HA\u0001\u0002\u0004\t\u0019,A\u0007d_J,7o\u0012:b]R,G\rI\u0001\bK:$G+[7f\u0003-)g\u000e\u001a+j[\u0016|F%Z9\u0015\t\u00055\u0012q\u0019\u0005\t\u0003ky\u0012\u0011!a\u0001+\u0006AQM\u001c3US6,\u0007%\u0001\boKb$X\t_3dkR|'/\u00133\u0002%9,\u0007\u0010^#yK\u000e,Ho\u001c:JI~#S-\u001d\u000b\u0005\u0003[\t\t\u000eC\u0005\u00026\t\n\t\u00111\u0001\u00024\u0006ya.\u001a=u\u000bb,7-\u001e;pe&#\u0007%A\nsK\u001eL7\u000f^3sK\u0012,\u00050Z2vi>\u00148/A\fsK\u001eL7\u000f^3sK\u0012,\u00050Z2vi>\u00148o\u0018\u0013fcR!\u0011QFAn\u0011%\t)$JA\u0001\u0002\u0004\t\u0019,\u0001\u000bsK\u001eL7\u000f^3sK\u0012,\u00050Z2vi>\u00148\u000fI\u0001\u0005S:LG\u000f\u0006\u0002\u0002.\u0005Q\u0012\r\u001a3QK:$\u0017N\\4SK\u001eL7\u000f^3s\u000bb,7-\u001e;peRQ\u0011QFAt\u0003W\fy/a=\t\r\u0005%\b\u00061\u0001\\\u0003))\u00070Z2vi>\u0014\u0018\n\u001a\u0005\b\u0003[D\u0003\u0019AA;\u0003\u001dA\u0017M\u001c3mKJDq!!=)\u0001\u0004\t\u0019,A\u0003d_J,7\u000fC\u0004\u0002v\"\u0002\r!a-\u0002\u00155,Wn\u001c:z\u0013:l%)\u0001\tsK\u001eL7\u000f^3s\u000bb,7-\u001e;peR!\u00111 B\u0001!\r9\u0015Q`\u0005\u0004\u0003\u007fD%a\u0002\"p_2,\u0017M\u001c\u0005\u0007\u0003SL\u0003\u0019A.\u0002'5\f'o[#yK\u000e,Ho\u001c:Ti\u0006\u0014H/\u001a3\u0015\r\u00055\"q\u0001B\u0005\u0011\u0019\tIO\u000ba\u00017\"9!1\u0002\u0016A\u0002\u0005\u0005\u0014aB1eIJ,7o]\u0001\u0005W&dG\u000e\u0006\u0003\u0002|\nE\u0001b\u0002B\u0006W\u0001\u0007\u0011\u0011\r\u000b\u0005\u0003w\u0014)\u0002\u0003\u0004\u0002j2\u0002\raW\u0001\u0013O\u0016$X\t_3dkR|'\u000fS1oI2,'\u000f\u0006\u0003\u0003\u001c\t\u0005\u0002#B$\u0003\u001e\u0005U\u0014b\u0001B\u0010\u0011\n1q\n\u001d;j_:Da!!;.\u0001\u0004Y\u0016A\b:f[\u0006Lg.\u001b8h+:\u0014VmZ5ti\u0016\u0014X\rZ#yK\u000e,Ho\u001c:t)\t\t\u0019,\u0001\tdkJ\u0014XM\u001c;Fq\u0016\u001cW\u000f^8sg\u0006\tr-\u001a;OKb$X\t_3dkR|'/\u00133\u0002\u0017}\u0013X\r\u001e:z\u0007>,h\u000e^\u0001\u0010?J,GO]=D_VtGo\u0018\u0013fcR!\u0011Q\u0006B\u0019\u0011%\t)DMA\u0001\u0002\u0004\t\u0019,\u0001\u0007`e\u0016$(/_\"pk:$\b%\u0001\u0006sKR\u0014\u0018pQ8v]R\f1#\u001b8de\u0016lWM\u001c;SKR\u0014\u0018pQ8v]R\fqB]3tKR\u0014V\r\u001e:z\u0007>,h\u000e^\u0001\r[\u0006\u00148NR5oSNDW\r\u001a\u000b\u0005\u0003[\u0011y\u0004C\u0004\u0003B]\u0002\r!!\u0007\u0002\u0011\u0015tGm\u0015;bi\u0016\f!\"[:GS:L7\u000f[3e+\t\tY0\u0001\u0005ekJ\fG/[8o\u0001")
+@ScalaSignature(bytes = "\u0006\u0001\t=c!\u0002\u001e<\u0001}*\u0005\u0002\u0003*\u0001\u0005\u000b\u0007I\u0011\u0001+\t\u0011a\u0003!\u0011!Q\u0001\nUC\u0001\"\u0017\u0001\u0003\u0006\u0004%\tA\u0017\u0005\tM\u0002\u0011\t\u0011)A\u00057\"Aq\r\u0001BC\u0002\u0013\u0005\u0001\u000e\u0003\u0005n\u0001\t\u0005\t\u0015!\u0003j\u0011!q\u0007A!b\u0001\n\u0003y\u0007\u0002\u0003=\u0001\u0005\u0003\u0005\u000b\u0011\u00029\t\u0011e\u0004!Q1A\u0005\u0002iD\u0011\"a\u0001\u0001\u0005\u0003\u0005\u000b\u0011B>\t\u000f\u0005\u0015\u0001\u0001\"\u0001\u0002\b!Y\u0011Q\u0003\u0001A\u0002\u0003\u0007I\u0011AA\f\u0011-\tI\u0003\u0001a\u0001\u0002\u0004%\t!a\u000b\t\u0017\u0005]\u0002\u00011A\u0001B\u0003&\u0011\u0011\u0004\u0005\f\u0003s\u0001\u0001\u0019!a\u0001\n\u0003\tY\u0004C\u0006\u0002T\u0001\u0001\r\u00111A\u0005\u0002\u0005U\u0003bCA-\u0001\u0001\u0007\t\u0011)Q\u0005\u0003{A1\"a\u0017\u0001\u0001\u0004\u0005\r\u0011\"\u0001\u0002^!Y\u0011q\r\u0001A\u0002\u0003\u0007I\u0011AA5\u0011-\ti\u0007\u0001a\u0001\u0002\u0003\u0006K!a\u0018\t\u0017\u0005=\u0004\u00011AA\u0002\u0013\u0005\u0011\u0011\u000f\u0005\f\u0003+\u0003\u0001\u0019!a\u0001\n\u0003\t9\nC\u0006\u0002\u001c\u0002\u0001\r\u0011!Q!\n\u0005M\u0004bCAO\u0001\u0001\u0007\t\u0019!C\u0001\u0003?C1\"a*\u0001\u0001\u0004\u0005\r\u0011\"\u0001\u0002*\"Y\u0011Q\u0016\u0001A\u0002\u0003\u0005\u000b\u0015BAQ\u0011-\ty\u000b\u0001a\u0001\u0002\u0004%\t!!-\t\u0017\u0005e\u0006\u00011AA\u0002\u0013\u0005\u00111\u0018\u0005\f\u0003\u007f\u0003\u0001\u0019!A!B\u0013\t\u0019\f\u0003\u0006\u0002B\u0002\u0001\r\u00111A\u0005\u0002QC1\"a1\u0001\u0001\u0004\u0005\r\u0011\"\u0001\u0002F\"Q\u0011\u0011\u001a\u0001A\u0002\u0003\u0005\u000b\u0015B+\t\u0017\u0005-\u0007\u00011AA\u0002\u0013%\u0011\u0011\u0017\u0005\f\u0003\u001b\u0004\u0001\u0019!a\u0001\n\u0013\ty\rC\u0006\u0002T\u0002\u0001\r\u0011!Q!\n\u0005M\u0006\"CAk\u0001\u0001\u0007I\u0011BAY\u0011%\t9\u000e\u0001a\u0001\n\u0013\tI\u000e\u0003\u0005\u0002^\u0002\u0001\u000b\u0015BAZ\u0011\u001d\ty\u000e\u0001C\u0005\u0003CDq!a9\u0001\t\u0003\t)\u000fC\u0004\u0002x\u0002!\t!!?\t\u000f\t\r\u0001\u0001\"\u0001\u0003\u0006!9!Q\u0002\u0001\u0005\u0002\t=\u0001b\u0002B\u0007\u0001\u0011\u0005!q\u0003\u0005\b\u0005;\u0001A\u0011\u0001B\u0010\u0011\u001d\u0011I\u0003\u0001C\u0001\u0005WAqA!\f\u0001\t\u0003\u0011Y\u0003C\u0004\u00030\u0001!\tAa\u000b\t\u0013\tE\u0002\u00011A\u0005\n\u0005E\u0006\"\u0003B\u001a\u0001\u0001\u0007I\u0011\u0002B\u001b\u0011!\u0011I\u0004\u0001Q!\n\u0005M\u0006b\u0002B\u001e\u0001\u0011\u0005\u0011\u0011\u0017\u0005\b\u0005{\u0001A\u0011\u0001B\u0016\u0011\u001d\u0011y\u0004\u0001C\u0001\u0003CDqA!\u0011\u0001\t\u0003\u0011\u0019\u0005C\u0004\u0003J\u0001!\tAa\u0013\t\r\t5\u0003\u0001\"\u0001U\u0005=\t\u0005\u000f\u001d7jG\u0006$\u0018n\u001c8J]\u001a|'B\u0001\u001f>\u0003\u0015\u0011\u0018-\u001f3q\u0015\tqt(\u0001\u0004eKBdw.\u001f\u0006\u0003\u0001\u0006\u000bQa\u001d9be.T!AQ\"\u0002\r\u0005\u0004\u0018m\u00195f\u0015\u0005!\u0015aA8sON\u0019\u0001A\u0012'\u0011\u0005\u001dSU\"\u0001%\u000b\u0003%\u000bQa]2bY\u0006L!a\u0013%\u0003\r\u0005s\u0017PU3g!\ti\u0005+D\u0001O\u0015\tyu(\u0001\u0005j]R,'O\\1m\u0013\t\tfJA\u0004M_\u001e<\u0017N\\4\u0002\u0013M$\u0018M\u001d;US6,7\u0001A\u000b\u0002+B\u0011qIV\u0005\u0003/\"\u0013A\u0001T8oO\u0006Q1\u000f^1siRKW.\u001a\u0011\u0002\u0005%$W#A.\u0011\u0005q\u001bgBA/b!\tq\u0006*D\u0001`\u0015\t\u00017+\u0001\u0004=e>|GOP\u0005\u0003E\"\u000ba\u0001\u0015:fI\u00164\u0017B\u00013f\u0005\u0019\u0019FO]5oO*\u0011!\rS\u0001\u0004S\u0012\u0004\u0013\u0001\u00023fg\u000e,\u0012!\u001b\t\u0003U.l\u0011aO\u0005\u0003Yn\u0012a#\u00119qY&\u001c\u0017\r^5p]\u0012+7o\u0019:jaRLwN\\\u0001\u0006I\u0016\u001c8\rI\u0001\u000bgV\u0014W.\u001b;ECR,W#\u00019\u0011\u0005E4X\"\u0001:\u000b\u0005M$\u0018\u0001B;uS2T\u0011!^\u0001\u0005U\u00064\u0018-\u0003\u0002xe\n!A)\u0019;f\u0003-\u0019XOY7ji\u0012\u000bG/\u001a\u0011\u0002\r\u0011\u0014\u0018N^3s+\u0005Y\bC\u0001?\u0000\u001b\u0005i(B\u0001@@\u0003\r\u0011\boY\u0005\u0004\u0003\u0003i(A\u0004*qG\u0016sG\r]8j]R\u0014VMZ\u0001\bIJLg/\u001a:!\u0003\u0019a\u0014N\\5u}Qa\u0011\u0011BA\u0006\u0003\u001b\ty!!\u0005\u0002\u0014A\u0011!\u000e\u0001\u0005\u0006%.\u0001\r!\u0016\u0005\u00063.\u0001\ra\u0017\u0005\u0006O.\u0001\r!\u001b\u0005\u0006].\u0001\r\u0001\u001d\u0005\u0006s.\u0001\ra_\u0001\u0006gR\fG/Z\u000b\u0003\u00033\u0001B!a\u0007\u0002\"9\u0019!.!\b\n\u0007\u0005}1(\u0001\tBaBd\u0017nY1uS>t7\u000b^1uK&!\u00111EA\u0013\u0005\u00151\u0016\r\\;f\u0013\r\t9\u0003\u0013\u0002\f\u000b:,X.\u001a:bi&|g.A\u0005ti\u0006$Xm\u0018\u0013fcR!\u0011QFA\u001a!\r9\u0015qF\u0005\u0004\u0003cA%\u0001B+oSRD\u0011\"!\u000e\u000e\u0003\u0003\u0005\r!!\u0007\u0002\u0007a$\u0013'\u0001\u0004ti\u0006$X\rI\u0001\nKb,7-\u001e;peN,\"!!\u0010\u0011\u000f\u0005}\u0012\u0011J.\u0002N5\u0011\u0011\u0011\t\u0006\u0005\u0003\u0007\n)%A\u0004nkR\f'\r\\3\u000b\u0007\u0005\u001d\u0003*\u0001\u0006d_2dWm\u0019;j_:LA!a\u0013\u0002B\t9\u0001*Y:i\u001b\u0006\u0004\bc\u00016\u0002P%\u0019\u0011\u0011K\u001e\u0003\u0019\u0015CXmY;u_J$Um]2\u0002\u001b\u0015DXmY;u_J\u001cx\fJ3r)\u0011\ti#a\u0016\t\u0013\u0005U\u0002#!AA\u0002\u0005u\u0012AC3yK\u000e,Ho\u001c:tA\u0005\u0019\u0012\r\u001a3sKN\u001cHk\\#yK\u000e,Ho\u001c:JIV\u0011\u0011q\f\t\b\u0003\u007f\tI%!\u0019\\!\ra\u00181M\u0005\u0004\u0003Kj(A\u0003*qG\u0006#GM]3tg\u00069\u0012\r\u001a3sKN\u001cHk\\#yK\u000e,Ho\u001c:JI~#S-\u001d\u000b\u0005\u0003[\tY\u0007C\u0005\u00026M\t\t\u00111\u0001\u0002`\u0005!\u0012\r\u001a3sKN\u001cHk\\#yK\u000e,Ho\u001c:JI\u0002\n1#\u001a=fGV$xN]%e)>D\u0015M\u001c3mKJ,\"!a\u001d\u0011\u000f\u0005}\u0012\u0011J.\u0002vA1\u0011qOAC\u0003\u0013k!!!\u001f\u000b\t\u0005m\u0014QP\u0001\u0004CBL'\u0002BA@\u0003\u0003\u000b1A]1z\u0015\t\t\u0019)\u0001\u0002j_&!\u0011qQA=\u0005-\t5\r^8s\u0011\u0006tG\r\\3\u0011\t\u0005-\u0015\u0011S\u0007\u0003\u0003\u001bS1!a$@\u0003!)\u00070Z2vi>\u0014\u0018\u0002BAJ\u0003\u001b\u0013QBU1z\tB+\u00050Z2vi>\u0014\u0018aF3yK\u000e,Ho\u001c:JIR{\u0007*\u00198eY\u0016\u0014x\fJ3r)\u0011\ti#!'\t\u0013\u0005Ub#!AA\u0002\u0005M\u0014\u0001F3yK\u000e,Ho\u001c:JIR{\u0007*\u00198eY\u0016\u0014\b%\u0001\tsK6|g/\u001a3Fq\u0016\u001cW\u000f^8sgV\u0011\u0011\u0011\u0015\t\u0007\u0003\u007f\t\u0019+!\u0014\n\t\u0005\u0015\u0016\u0011\t\u0002\f\u0003J\u0014\u0018-\u001f\"vM\u001a,'/\u0001\u000bsK6|g/\u001a3Fq\u0016\u001cW\u000f^8sg~#S-\u001d\u000b\u0005\u0003[\tY\u000bC\u0005\u00026e\t\t\u00111\u0001\u0002\"\u0006\t\"/Z7pm\u0016$W\t_3dkR|'o\u001d\u0011\u0002\u0019\r|'/Z:He\u0006tG/\u001a3\u0016\u0005\u0005M\u0006cA$\u00026&\u0019\u0011q\u0017%\u0003\u0007%sG/\u0001\td_J,7o\u0012:b]R,Gm\u0018\u0013fcR!\u0011QFA_\u0011%\t)\u0004HA\u0001\u0002\u0004\t\u0019,A\u0007d_J,7o\u0012:b]R,G\rI\u0001\bK:$G+[7f\u0003-)g\u000e\u001a+j[\u0016|F%Z9\u0015\t\u00055\u0012q\u0019\u0005\t\u0003ky\u0012\u0011!a\u0001+\u0006AQM\u001c3US6,\u0007%\u0001\boKb$X\t_3dkR|'/\u00133\u0002%9,\u0007\u0010^#yK\u000e,Ho\u001c:JI~#S-\u001d\u000b\u0005\u0003[\t\t\u000eC\u0005\u00026\t\n\t\u00111\u0001\u00024\u0006ya.\u001a=u\u000bb,7-\u001e;pe&#\u0007%A\nsK\u001eL7\u000f^3sK\u0012,\u00050Z2vi>\u00148/A\fsK\u001eL7\u000f^3sK\u0012,\u00050Z2vi>\u00148o\u0018\u0013fcR!\u0011QFAn\u0011%\t)$JA\u0001\u0002\u0004\t\u0019,\u0001\u000bsK\u001eL7\u000f^3sK\u0012,\u00050Z2vi>\u00148\u000fI\u0001\u0005S:LG\u000f\u0006\u0002\u0002.\u0005Q\u0012\r\u001a3QK:$\u0017N\\4SK\u001eL7\u000f^3s\u000bb,7-\u001e;peRQ\u0011QFAt\u0003W\fy/a=\t\r\u0005%\b\u00061\u0001\\\u0003))\u00070Z2vi>\u0014\u0018\n\u001a\u0005\b\u0003[D\u0003\u0019AA;\u0003\u001dA\u0017M\u001c3mKJDq!!=)\u0001\u0004\t\u0019,A\u0003d_J,7\u000fC\u0004\u0002v\"\u0002\r!a-\u0002\u00155,Wn\u001c:z\u0013:l%)\u0001\tsK\u001eL7\u000f^3s\u000bb,7-\u001e;peR!\u00111 B\u0001!\r9\u0015Q`\u0005\u0004\u0003\u007fD%a\u0002\"p_2,\u0017M\u001c\u0005\u0007\u0003SL\u0003\u0019A.\u0002'5\f'o[#yK\u000e,Ho\u001c:Ti\u0006\u0014H/\u001a3\u0015\r\u00055\"q\u0001B\u0005\u0011\u0019\tIO\u000ba\u00017\"9!1\u0002\u0016A\u0002\u0005\u0005\u0014aB1eIJ,7o]\u0001\u0005W&dG\u000e\u0006\u0004\u0002|\nE!1\u0003\u0005\b\u0005\u0017Y\u0003\u0019AA1\u0011\u001d\u0011)b\u000ba\u0001\u0003w\fQb\u001d5vi\u0012|wO\\!di>\u0014HCBA~\u00053\u0011Y\u0002\u0003\u0004\u0002j2\u0002\ra\u0017\u0005\b\u0005+a\u0003\u0019AA~\u0003I9W\r^#yK\u000e,Ho\u001c:IC:$G.\u001a:\u0015\t\t\u0005\"q\u0005\t\u0006\u000f\n\r\u0012QO\u0005\u0004\u0005KA%AB(qi&|g\u000e\u0003\u0004\u0002j6\u0002\raW\u0001\u001fe\u0016l\u0017-\u001b8j]\u001e,fNU3hSN$XM]3e\u000bb,7-\u001e;peN$\"!a-\u0002!\r,(O]3oi\u0016CXmY;u_J\u001c\u0018!E4fi:+\u0007\u0010^#yK\u000e,Ho\u001c:JI\u0006YqL]3uef\u001cu.\u001e8u\u0003=y&/\u001a;ss\u000e{WO\u001c;`I\u0015\fH\u0003BA\u0017\u0005oA\u0011\"!\u000e3\u0003\u0003\u0005\r!a-\u0002\u0019}\u0013X\r\u001e:z\u0007>,h\u000e\u001e\u0011\u0002\u0015I,GO]=D_VtG/A\nj]\u000e\u0014X-\\3oiJ+GO]=D_VtG/A\bsKN,GOU3uef\u001cu.\u001e8u\u00031i\u0017M]6GS:L7\u000f[3e)\u0011\tiC!\u0012\t\u000f\t\u001ds\u00071\u0001\u0002\u001a\u0005AQM\u001c3Ti\u0006$X-\u0001\u0006jg\u001aKg.[:iK\u0012,\"!a?\u0002\u0011\u0011,(/\u0019;j_:\u0004")
 public class ApplicationInfo implements Logging
 {
     private final long startTime;
     private final String id;
     private final ApplicationDescription desc;
     private final Date submitDate;
     private final RpcEndpointRef driver;
@@ -248,29 +248,31 @@
         return b;
     }
     
     public void markExecutorStarted(final String executorId, final RpcAddress address) {
         this.addressToExecutorId().update((Object)address, (Object)executorId);
     }
     
-    public boolean kill(final RpcAddress address) {
-        return this.addressToExecutorId().contains((Object)address) && this.kill((String)this.addressToExecutorId().apply((Object)address));
+    public boolean kill(final RpcAddress address, final boolean shutdownActor) {
+        return this.addressToExecutorId().contains((Object)address) && this.kill((String)this.addressToExecutorId().apply((Object)address), shutdownActor);
     }
     
-    public boolean kill(final String executorId) {
+    public boolean kill(final String executorId, final boolean shutdownActor) {
         boolean b;
         if (this.executors().contains((Object)executorId)) {
             final ExecutorDesc exec = (ExecutorDesc)this.executors().apply((Object)executorId);
             if (exec.registered()) {
                 this.registeredExecutors_$eq(this.registeredExecutors() - 1);
             }
             this.removedExecutors().$plus$eq(this.executors().apply((Object)executorId));
             this.executors().$minus$eq((Object)executorId);
             this.coresGranted_$eq(this.coresGranted() - exec.cores());
-            RayExecutorUtils.exitExecutor((ActorHandle)this.executorIdToHandler().apply((Object)executorId));
+            if (shutdownActor) {
+                RayExecutorUtils.exitExecutor((ActorHandle)this.executorIdToHandler().apply((Object)executorId));
+            }
             this.executorIdToHandler().$minus$eq((Object)executorId);
             b = true;
         }
         else {
             b = false;
         }
         return b;
```

### org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1.class

#### javap -verbose -constants -s -l -private {}

```diff
@@ -1,8 +1,8 @@
-  SHA-256 checksum cd3e6767632aa2a496997ef2fe790d580840acd00adc31678a4b95d9afbdf227
+  SHA-256 checksum 40f4343335bd46b132e85f6ac92399ae30e289205888427a2a087ef3752d7936
   Compiled from "RayAppMaster.scala"
 public final class org.apache.spark.deploy.raydp.RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1 extends scala.runtime.AbstractPartialFunction<java.lang.Object, scala.runtime.BoxedUnit> implements scala.Serializable
   minor version: 0
   major version: 52
   flags: (0x0031) ACC_PUBLIC, ACC_FINAL, ACC_SUPER
   this_class: #2                          // org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1
   super_class: #5                         // scala/runtime/AbstractPartialFunction
@@ -435,16 +435,16 @@
   #426 = Utf8               ()V
   #427 = NameAndType        #425:#426     // org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$requestNewExecutor:()V
   #428 = Methodref          #10.#427      // org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$requestNewExecutor:()V
   #429 = Utf8               $anonfun$applyOrElse$5
   #430 = Utf8               (Lorg/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1;Lscala/runtime/BooleanRef;Ljava/lang/String;)V
   #431 = Utf8               success$1
   #432 = Utf8               kill
-  #433 = NameAndType        #432:#63      // kill:(Ljava/lang/String;)Z
-  #434 = Methodref          #61.#433      // org/apache/spark/deploy/raydp/ApplicationInfo.kill:(Ljava/lang/String;)Z
+  #433 = NameAndType        #432:#79      // kill:(Ljava/lang/String;Z)Z
+  #434 = Methodref          #61.#433      // org/apache/spark/deploy/raydp/ApplicationInfo.kill:(Ljava/lang/String;Z)Z
   #435 = Utf8               (Lorg/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint;Lorg/apache/spark/rpc/RpcCallContext;)V
   #436 = NameAndType        #138:#426     // "<init>":()V
   #437 = Methodref          #5.#436       // scala/runtime/AbstractPartialFunction."<init>":()V
   #438 = NameAndType        #429:#430     // $anonfun$applyOrElse$5:(Lorg/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1;Lscala/runtime/BooleanRef;Ljava/lang/String;)V
   #439 = Methodref          #2.#438       // org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$5:(Lorg/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1;Lscala/runtime/BooleanRef;Ljava/lang/String;)V
   #440 = Utf8               $deserializeLambda$
   #441 = Utf8               (Ljava/lang/invoke/SerializedLambda;)Ljava/lang/Object;
@@ -1099,37 +1099,38 @@
       $this                          final synthetic
       x$3                            final
 
   public static final void $anonfun$applyOrElse$5(org.apache.spark.deploy.raydp.RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1, scala.runtime.BooleanRef, java.lang.String);
     descriptor: (Lorg/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1;Lscala/runtime/BooleanRef;Ljava/lang/String;)V
     flags: (0x1019) ACC_PUBLIC, ACC_STATIC, ACC_FINAL, ACC_SYNTHETIC
     Code:
-      stack=2, locals=3, args_size=3
+      stack=3, locals=3, args_size=3
          0: aload_0
          1: getfield      #55                 // Field $outer:Lorg/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint;
          4: invokevirtual #59                 // Method org/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint.org$apache$spark$deploy$raydp$RayAppMaster$RayAppMasterEndpoint$$appInfo:()Lorg/apache/spark/deploy/raydp/ApplicationInfo;
          7: aload_2
-         8: invokevirtual #434                // Method org/apache/spark/deploy/raydp/ApplicationInfo.kill:(Ljava/lang/String;)Z
-        11: ifne          22
-        14: aload_1
-        15: iconst_0
-        16: putfield      #292                // Field scala/runtime/BooleanRef.elem:Z
-        19: goto          22
-        22: return
+         8: iconst_1
+         9: invokevirtual #434                // Method org/apache/spark/deploy/raydp/ApplicationInfo.kill:(Ljava/lang/String;Z)Z
+        12: ifne          23
+        15: aload_1
+        16: iconst_0
+        17: putfield      #292                // Field scala/runtime/BooleanRef.elem:Z
+        20: goto          23
+        23: return
       StackMapTable: number_of_entries = 1
-        frame_type = 22 /* same */
+        frame_type = 23 /* same */
       LineNumberTable:
         line 186: 0
-        line 187: 14
-        line 186: 22
+        line 187: 15
+        line 186: 23
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
-            0      23     0 $this   Lorg/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1;
-            0      23     1 success$1   Lscala/runtime/BooleanRef;
-            0      23     2 executorId   Ljava/lang/String;
+            0      24     0 $this   Lorg/apache/spark/deploy/raydp/RayAppMaster$RayAppMasterEndpoint$$anonfun$receiveAndReply$1;
+            0      24     1 success$1   Lscala/runtime/BooleanRef;
+            0      24     2 executorId   Ljava/lang/String;
     MethodParameters:
       Name                           Flags
       $this                          final synthetic
       success$1                      final
       executorId                     final
 
   public static final int $anonfun$applyOrElse$6();
```

### org/apache/spark/deploy/raydp/RayAppMaster$.class

#### javap -verbose -constants -s -l -private {}

```diff
@@ -1,8 +1,8 @@
-  SHA-256 checksum 7bb3b0231d94a51103adfce77b50dbff7de48c1d5ac75c977edfcd24100b37e6
+  SHA-256 checksum 37eca51b035ff19b4f10467e263ad767f059727f308e9eeda79aa9fc79f6accd
   Compiled from "RayAppMaster.scala"
 public final class org.apache.spark.deploy.raydp.RayAppMaster$ implements scala.Serializable
   minor version: 0
   major version: 52
   flags: (0x0031) ACC_PUBLIC, ACC_FINAL, ACC_SUPER
   this_class: #2                          // org/apache/spark/deploy/raydp/RayAppMaster$
   super_class: #4                         // java/lang/Object
@@ -250,43 +250,43 @@
     flags: (0x0001) ACC_PUBLIC
     Code:
       stack=1, locals=1, args_size=1
          0: aload_0
          1: getfield      #31                 // Field ENV_NAME:Ljava/lang/String;
          4: areturn
       LineNumberTable:
-        line 336: 0
+        line 346: 0
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
             0       5     0  this   Lorg/apache/spark/deploy/raydp/RayAppMaster$;
 
   public java.lang.String ENDPOINT_NAME();
     descriptor: ()Ljava/lang/String;
     flags: (0x0001) ACC_PUBLIC
     Code:
       stack=1, locals=1, args_size=1
          0: aload_0
          1: getfield      #34                 // Field ENDPOINT_NAME:Ljava/lang/String;
          4: areturn
       LineNumberTable:
-        line 337: 0
+        line 347: 0
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
             0       5     0  this   Lorg/apache/spark/deploy/raydp/RayAppMaster$;
 
   public java.lang.String ACTOR_NAME();
     descriptor: ()Ljava/lang/String;
     flags: (0x0001) ACC_PUBLIC
     Code:
       stack=1, locals=1, args_size=1
          0: aload_0
          1: getfield      #36                 // Field ACTOR_NAME:Ljava/lang/String;
          4: areturn
       LineNumberTable:
-        line 338: 0
+        line 348: 0
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
             0       5     0  this   Lorg/apache/spark/deploy/raydp/RayAppMaster$;
 
   public void setProperties(java.lang.String);
     descriptor: (Ljava/lang/String;)V
     flags: (0x0001) ACC_PUBLIC
@@ -331,18 +331,18 @@
         89: invokeinterface #133,  2          // InterfaceMethod scala/collection/immutable/Map.foreach:(Lscala/Function1;)V
         94: invokestatic  #139                // Method io/ray/runtime/config/RayConfig.create:()Lio/ray/runtime/config/RayConfig;
         97: ldc           #141                // String ray.session-dir
         99: invokestatic  #147                // Method java/lang/System.getProperty:(Ljava/lang/String;)Ljava/lang/String;
        102: invokevirtual #150                // Method io/ray/runtime/config/RayConfig.setSessionDir:(Ljava/lang/String;)V
        105: return
       LineNumberTable:
-        line 341: 0
-        line 342: 4
-        line 343: 83
-        line 347: 94
+        line 351: 0
+        line 352: 4
+        line 353: 83
+        line 357: 94
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
             4     101     2 formats   Lorg/json4s/DefaultFormats$;
            83      22     3 parsed   Lscala/collection/immutable/Map;
             0     106     0  this   Lorg/apache/spark/deploy/raydp/RayAppMaster$;
             0     106     1 properties   Ljava/lang/String;
     MethodParameters:
@@ -353,28 +353,28 @@
     descriptor: ()V
     flags: (0x0001) ACC_PUBLIC
     Code:
       stack=0, locals=1, args_size=1
          0: invokestatic  #159                // Method io/ray/api/Ray.shutdown:()V
          3: return
       LineNumberTable:
-        line 351: 0
+        line 361: 0
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
             0       4     0  this   Lorg/apache/spark/deploy/raydp/RayAppMaster$;
 
   private java.lang.Object readResolve();
     descriptor: ()Ljava/lang/Object;
     flags: (0x0002) ACC_PRIVATE
     Code:
       stack=1, locals=1, args_size=1
          0: getstatic     #163                // Field MODULE$:Lorg/apache/spark/deploy/raydp/RayAppMaster$;
          3: areturn
       LineNumberTable:
-        line 335: 0
+        line 345: 0
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
             0       4     0  this   Lorg/apache/spark/deploy/raydp/RayAppMaster$;
 
   public static final java.lang.String $anonfun$setProperties$1(scala.Tuple2);
     descriptor: (Lscala/Tuple2;)Ljava/lang/String;
     flags: (0x1019) ACC_PUBLIC, ACC_STATIC, ACC_FINAL, ACC_SYNTHETIC
@@ -411,17 +411,17 @@
           locals = [ top, class scala/Tuple2 ]
         frame_type = 2 /* same */
         frame_type = 255 /* full_frame */
           offset_delta = 8
           locals = [ class scala/Tuple2, class java/lang/String, class scala/Tuple2, class java/lang/String, class java/lang/String ]
           stack = []
       LineNumberTable:
-        line 343: 0
-        line 344: 23
-        line 343: 33
+        line 353: 0
+        line 354: 23
+        line 353: 33
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
            14      19     3   key   Ljava/lang/String;
            23      10     4 value   Ljava/lang/String;
             0      47     0  x0$1   Lscala/Tuple2;
     MethodParameters:
       Name                           Flags
@@ -443,19 +443,19 @@
         15: ldc           #189                // String RAY_APP_MASTER
         17: putfield      #34                 // Field ENDPOINT_NAME:Ljava/lang/String;
         20: aload_0
         21: ldc           #189                // String RAY_APP_MASTER
         23: putfield      #36                 // Field ACTOR_NAME:Ljava/lang/String;
         26: return
       LineNumberTable:
-        line 335: 0
-        line 336: 8
-        line 337: 14
-        line 338: 20
-        line 335: 26
+        line 345: 0
+        line 346: 8
+        line 347: 14
+        line 348: 20
+        line 345: 26
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
             0      27     0  this   Lorg/apache/spark/deploy/raydp/RayAppMaster$;
 
   private static java.lang.Object $deserializeLambda$(java.lang.invoke.SerializedLambda);
     descriptor: (Ljava/lang/invoke/SerializedLambda;)Ljava/lang/Object;
     flags: (0x100a) ACC_PRIVATE, ACC_STATIC, ACC_SYNTHETIC
```

## raydp/jars/raydp-agent-1.7.0-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,17 +1,17 @@
 Zip file size: 7071 bytes, number of entries: 15
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/
--rw-r--r--  2.0 unx      127 b- defN 23-Sep-19 00:47 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/slf4j/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/slf4j/impl/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/raydp-agent/
--rw-r--r--  2.0 unx     3934 b- defN 23-Sep-19 00:47 org/slf4j/impl/StaticLoggerBinder.class
--rw-r--r--  2.0 unx     4469 b- defN 23-Sep-19 00:47 org/apache/spark/raydp/Agent.class
--rw-r--r--  2.0 unx     2292 b- defN 23-Sep-19 00:46 META-INF/maven/com.intel/raydp-agent/pom.xml
--rw-r--r--  2.0 unx       64 b- defN 23-Sep-19 00:47 META-INF/maven/com.intel/raydp-agent/pom.properties
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/
+-rw-r--r--  2.0 unx      127 b- defN 24-Apr-10 00:48 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/slf4j/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/slf4j/impl/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-agent/
+-rw-r--r--  2.0 unx     4469 b- defN 24-Apr-10 00:48 org/apache/spark/raydp/Agent.class
+-rw-r--r--  2.0 unx     3934 b- defN 24-Apr-10 00:48 org/slf4j/impl/StaticLoggerBinder.class
+-rw-r--r--  2.0 unx     2292 b- defN 24-Apr-10 00:47 META-INF/maven/com.intel/raydp-agent/pom.xml
+-rw-r--r--  2.0 unx       64 b- defN 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-agent/pom.properties
 15 files, 10886 bytes uncompressed, 5201 bytes compressed:  52.2%
```

### zipnote «TEMP»/diffoscope_1d0ljn3y_/tmp5l5yfq85_.zip

```diff
@@ -3,42 +3,42 @@
 
 Filename: META-INF/MANIFEST.MF
 Comment: 
 
 Filename: org/
 Comment: 
 
-Filename: org/slf4j/
+Filename: org/apache/
 Comment: 
 
-Filename: org/slf4j/impl/
+Filename: org/apache/spark/
 Comment: 
 
-Filename: org/apache/
+Filename: org/apache/spark/raydp/
 Comment: 
 
-Filename: org/apache/spark/
+Filename: org/slf4j/
 Comment: 
 
-Filename: org/apache/spark/raydp/
+Filename: org/slf4j/impl/
 Comment: 
 
 Filename: META-INF/maven/
 Comment: 
 
 Filename: META-INF/maven/com.intel/
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-agent/
 Comment: 
 
-Filename: org/slf4j/impl/StaticLoggerBinder.class
+Filename: org/apache/spark/raydp/Agent.class
 Comment: 
 
-Filename: org/apache/spark/raydp/Agent.class
+Filename: org/slf4j/impl/StaticLoggerBinder.class
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-agent/pom.xml
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-agent/pom.properties
 Comment:
```

## raydp/jars/raydp-shims-common-1.7.0-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,25 +1,25 @@
 Zip file size: 16000 bytes, number of entries: 23
--rw-r--r--  2.0 unx       82 b- defN 23-Sep-19 00:47 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/executor/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/raydp/shims/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/raydp-shims-common/
--rw-r--r--  2.0 unx     1857 b- defN 23-Sep-19 00:47 org/apache/spark/executor/RayDPExecutorBackendFactory.class
--rw-r--r--  2.0 unx      629 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/ShimDescriptor.class
--rw-r--r--  2.0 unx     9721 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/SparkShimLoader$.class
--rw-r--r--  2.0 unx     5614 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/SparkShimDescriptor.class
--rw-r--r--  2.0 unx      725 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/SparkShimProvider.class
--rw-r--r--  2.0 unx     1492 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/SparkShimLoader.class
--rw-r--r--  2.0 unx     2219 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/SparkShimDescriptor$.class
--rw-r--r--  2.0 unx     1756 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/SparkShims.class
--rw-r--r--  2.0 unx     4245 b- defN 23-Sep-19 00:46 META-INF/maven/com.intel/raydp-shims-common/pom.xml
--rw-r--r--  2.0 unx       71 b- defN 23-Sep-19 00:47 META-INF/maven/com.intel/raydp-shims-common/pom.properties
+-rw-r--r--  2.0 unx       82 b- defN 24-Apr-10 00:48 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/executor/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/shims/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-shims-common/
+-rw-r--r--  2.0 unx     1857 b- defN 24-Apr-10 00:48 org/apache/spark/executor/RayDPExecutorBackendFactory.class
+-rw-r--r--  2.0 unx      725 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/SparkShimProvider.class
+-rw-r--r--  2.0 unx     1492 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/SparkShimLoader.class
+-rw-r--r--  2.0 unx     1756 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/SparkShims.class
+-rw-r--r--  2.0 unx      629 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/ShimDescriptor.class
+-rw-r--r--  2.0 unx     2219 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/SparkShimDescriptor$.class
+-rw-r--r--  2.0 unx     5614 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/SparkShimDescriptor.class
+-rw-r--r--  2.0 unx     9721 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/SparkShimLoader$.class
+-rw-r--r--  2.0 unx     4245 b- defN 24-Apr-10 00:47 META-INF/maven/com.intel/raydp-shims-common/pom.xml
+-rw-r--r--  2.0 unx       71 b- defN 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-shims-common/pom.properties
 23 files, 28411 bytes uncompressed, 12834 bytes compressed:  54.8%
```

### zipnote «TEMP»/diffoscope_1d0ljn3y_/tmptq3gnhw6_.zip

```diff
@@ -36,33 +36,33 @@
 
 Filename: META-INF/maven/com.intel/raydp-shims-common/
 Comment: 
 
 Filename: org/apache/spark/executor/RayDPExecutorBackendFactory.class
 Comment: 
 
-Filename: com/intel/raydp/shims/ShimDescriptor.class
+Filename: com/intel/raydp/shims/SparkShimProvider.class
 Comment: 
 
-Filename: com/intel/raydp/shims/SparkShimLoader$.class
+Filename: com/intel/raydp/shims/SparkShimLoader.class
 Comment: 
 
-Filename: com/intel/raydp/shims/SparkShimDescriptor.class
+Filename: com/intel/raydp/shims/SparkShims.class
 Comment: 
 
-Filename: com/intel/raydp/shims/SparkShimProvider.class
+Filename: com/intel/raydp/shims/ShimDescriptor.class
 Comment: 
 
-Filename: com/intel/raydp/shims/SparkShimLoader.class
+Filename: com/intel/raydp/shims/SparkShimDescriptor$.class
 Comment: 
 
-Filename: com/intel/raydp/shims/SparkShimDescriptor$.class
+Filename: com/intel/raydp/shims/SparkShimDescriptor.class
 Comment: 
 
-Filename: com/intel/raydp/shims/SparkShims.class
+Filename: com/intel/raydp/shims/SparkShimLoader$.class
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-common/pom.xml
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-common/pom.properties
 Comment:
```

## raydp/jars/raydp-shims-spark322-1.7.0-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,32 +1,32 @@
 Zip file size: 14050 bytes, number of entries: 30
--rw-r--r--  2.0 unx       82 b- defN 23-Sep-19 00:47 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/executor/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/executor/spark322/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/sql/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/sql/spark322/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/spark322/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/raydp/shims/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/raydp/shims/spark322/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/services/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/raydp-shims-spark322/
--rw-r--r--  2.0 unx     2928 b- defN 23-Sep-19 00:47 org/apache/spark/executor/spark322/RayDPSpark322ExecutorBackendFactory.class
--rw-r--r--  2.0 unx     1385 b- defN 23-Sep-19 00:47 org/apache/spark/sql/spark322/SparkSqlUtils$.class
--rw-r--r--  2.0 unx     1310 b- defN 23-Sep-19 00:47 org/apache/spark/sql/spark322/SparkSqlUtils.class
--rw-r--r--  2.0 unx      875 b- defN 23-Sep-19 00:47 org/apache/spark/spark322/TaskContextUtils.class
--rw-r--r--  2.0 unx     1571 b- defN 23-Sep-19 00:47 org/apache/spark/spark322/TaskContextUtils$.class
--rw-r--r--  2.0 unx     2994 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/spark322/Spark322Shims.class
--rw-r--r--  2.0 unx     2630 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/spark322/SparkShimProvider$.class
--rw-r--r--  2.0 unx     3013 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/spark322/SparkShimProvider.class
--rw-r--r--  2.0 unx       49 b- defN 23-Sep-19 00:47 META-INF/services/com.intel.raydp.shims.SparkShimProvider
--rw-r--r--  2.0 unx     4021 b- defN 23-Sep-19 00:46 META-INF/maven/com.intel/raydp-shims-spark322/pom.xml
--rw-r--r--  2.0 unx       73 b- defN 23-Sep-19 00:47 META-INF/maven/com.intel/raydp-shims-spark322/pom.properties
+-rw-r--r--  2.0 unx       82 b- defN 24-Apr-10 00:48 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/sql/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/sql/spark322/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/executor/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/executor/spark322/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/spark322/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/shims/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/shims/spark322/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/services/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-shims-spark322/
+-rw-r--r--  2.0 unx     1385 b- defN 24-Apr-10 00:48 org/apache/spark/sql/spark322/SparkSqlUtils$.class
+-rw-r--r--  2.0 unx     1310 b- defN 24-Apr-10 00:48 org/apache/spark/sql/spark322/SparkSqlUtils.class
+-rw-r--r--  2.0 unx     2928 b- defN 24-Apr-10 00:48 org/apache/spark/executor/spark322/RayDPSpark322ExecutorBackendFactory.class
+-rw-r--r--  2.0 unx     1571 b- defN 24-Apr-10 00:48 org/apache/spark/spark322/TaskContextUtils$.class
+-rw-r--r--  2.0 unx      875 b- defN 24-Apr-10 00:48 org/apache/spark/spark322/TaskContextUtils.class
+-rw-r--r--  2.0 unx     3013 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark322/SparkShimProvider.class
+-rw-r--r--  2.0 unx     2630 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark322/SparkShimProvider$.class
+-rw-r--r--  2.0 unx     2994 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark322/Spark322Shims.class
+-rw-r--r--  2.0 unx       49 b- defN 24-Apr-10 00:48 META-INF/services/com.intel.raydp.shims.SparkShimProvider
+-rw-r--r--  2.0 unx     4021 b- defN 24-Apr-10 00:47 META-INF/maven/com.intel/raydp-shims-spark322/pom.xml
+-rw-r--r--  2.0 unx       73 b- defN 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-shims-spark322/pom.properties
 30 files, 20931 bytes uncompressed, 9774 bytes compressed:  53.3%
```

### zipnote «TEMP»/diffoscope_1d0ljn3y_/tmp2beyilv0_.zip

```diff
@@ -9,24 +9,24 @@
 
 Filename: org/apache/
 Comment: 
 
 Filename: org/apache/spark/
 Comment: 
 
-Filename: org/apache/spark/executor/
+Filename: org/apache/spark/sql/
 Comment: 
 
-Filename: org/apache/spark/executor/spark322/
+Filename: org/apache/spark/sql/spark322/
 Comment: 
 
-Filename: org/apache/spark/sql/
+Filename: org/apache/spark/executor/
 Comment: 
 
-Filename: org/apache/spark/sql/spark322/
+Filename: org/apache/spark/executor/spark322/
 Comment: 
 
 Filename: org/apache/spark/spark322/
 Comment: 
 
 Filename: com/
 Comment: 
@@ -51,36 +51,36 @@
 
 Filename: META-INF/maven/com.intel/
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-spark322/
 Comment: 
 
-Filename: org/apache/spark/executor/spark322/RayDPSpark322ExecutorBackendFactory.class
-Comment: 
-
 Filename: org/apache/spark/sql/spark322/SparkSqlUtils$.class
 Comment: 
 
 Filename: org/apache/spark/sql/spark322/SparkSqlUtils.class
 Comment: 
 
-Filename: org/apache/spark/spark322/TaskContextUtils.class
+Filename: org/apache/spark/executor/spark322/RayDPSpark322ExecutorBackendFactory.class
 Comment: 
 
 Filename: org/apache/spark/spark322/TaskContextUtils$.class
 Comment: 
 
-Filename: com/intel/raydp/shims/spark322/Spark322Shims.class
+Filename: org/apache/spark/spark322/TaskContextUtils.class
+Comment: 
+
+Filename: com/intel/raydp/shims/spark322/SparkShimProvider.class
 Comment: 
 
 Filename: com/intel/raydp/shims/spark322/SparkShimProvider$.class
 Comment: 
 
-Filename: com/intel/raydp/shims/spark322/SparkShimProvider.class
+Filename: com/intel/raydp/shims/spark322/Spark322Shims.class
 Comment: 
 
 Filename: META-INF/services/com.intel.raydp.shims.SparkShimProvider
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-spark322/pom.xml
 Comment:
```

## raydp/jars/raydp-shims-spark330-1.7.0-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,33 +1,33 @@
-Zip file size: 15151 bytes, number of entries: 31
--rw-r--r--  2.0 unx       82 b- defN 23-Sep-19 00:47 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/spark330/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/executor/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/executor/spark330/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/sql/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 org/apache/spark/sql/spark330/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/raydp/shims/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 com/intel/raydp/shims/spark330/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/services/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/maven/com.intel/raydp-shims-spark330/
--rw-r--r--  2.0 unx      875 b- defN 23-Sep-19 00:47 org/apache/spark/spark330/TaskContextUtils.class
--rw-r--r--  2.0 unx     1625 b- defN 23-Sep-19 00:47 org/apache/spark/spark330/TaskContextUtils$.class
--rw-r--r--  2.0 unx     2931 b- defN 23-Sep-19 00:47 org/apache/spark/executor/spark330/RayDPSpark330ExecutorBackendFactory.class
--rw-r--r--  2.0 unx     2841 b- defN 23-Sep-19 00:47 org/apache/spark/executor/RayCoarseGrainedExecutorBackend.class
--rw-r--r--  2.0 unx     1169 b- defN 23-Sep-19 00:47 org/apache/spark/sql/spark330/SparkSqlUtils$.class
--rw-r--r--  2.0 unx     1310 b- defN 23-Sep-19 00:47 org/apache/spark/sql/spark330/SparkSqlUtils.class
--rw-r--r--  2.0 unx     1781 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/spark330/SparkShimProvider$.class
--rw-r--r--  2.0 unx     2345 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/spark330/SparkShimProvider.class
--rw-r--r--  2.0 unx     2994 b- defN 23-Sep-19 00:47 com/intel/raydp/shims/spark330/Spark330Shims.class
--rw-r--r--  2.0 unx       49 b- defN 23-Sep-19 00:47 META-INF/services/com.intel.raydp.shims.SparkShimProvider
--rw-r--r--  2.0 unx     3867 b- defN 23-Sep-19 00:46 META-INF/maven/com.intel/raydp-shims-spark330/pom.xml
--rw-r--r--  2.0 unx       73 b- defN 23-Sep-19 00:47 META-INF/maven/com.intel/raydp-shims-spark330/pom.properties
-31 files, 21942 bytes uncompressed, 10673 bytes compressed:  51.4%
+Zip file size: 15256 bytes, number of entries: 31
+-rw-r--r--  2.0 unx       82 b- defN 24-Apr-10 00:48 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/spark330/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/sql/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/sql/spark330/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/executor/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/executor/spark330/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/shims/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/shims/spark330/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/services/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-shims-spark330/
+-rw-r--r--  2.0 unx     1625 b- defN 24-Apr-10 00:48 org/apache/spark/spark330/TaskContextUtils$.class
+-rw-r--r--  2.0 unx      875 b- defN 24-Apr-10 00:48 org/apache/spark/spark330/TaskContextUtils.class
+-rw-r--r--  2.0 unx     1169 b- defN 24-Apr-10 00:48 org/apache/spark/sql/spark330/SparkSqlUtils$.class
+-rw-r--r--  2.0 unx     1310 b- defN 24-Apr-10 00:48 org/apache/spark/sql/spark330/SparkSqlUtils.class
+-rw-r--r--  2.0 unx     2931 b- defN 24-Apr-10 00:48 org/apache/spark/executor/spark330/RayDPSpark330ExecutorBackendFactory.class
+-rw-r--r--  2.0 unx     2841 b- defN 24-Apr-10 00:48 org/apache/spark/executor/RayCoarseGrainedExecutorBackend.class
+-rw-r--r--  2.0 unx     2479 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark330/SparkShimProvider.class
+-rw-r--r--  2.0 unx     1945 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark330/SparkShimProvider$.class
+-rw-r--r--  2.0 unx     2994 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark330/Spark330Shims.class
+-rw-r--r--  2.0 unx       49 b- defN 24-Apr-10 00:48 META-INF/services/com.intel.raydp.shims.SparkShimProvider
+-rw-r--r--  2.0 unx     3867 b- defN 24-Apr-10 00:47 META-INF/maven/com.intel/raydp-shims-spark330/pom.xml
+-rw-r--r--  2.0 unx       73 b- defN 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-shims-spark330/pom.properties
+31 files, 22240 bytes uncompressed, 10778 bytes compressed:  51.5%
```

### zipnote «TEMP»/diffoscope_1d0ljn3y_/tmpycqflfcx_.zip

```diff
@@ -12,24 +12,24 @@
 
 Filename: org/apache/spark/
 Comment: 
 
 Filename: org/apache/spark/spark330/
 Comment: 
 
-Filename: org/apache/spark/executor/
+Filename: org/apache/spark/sql/
 Comment: 
 
-Filename: org/apache/spark/executor/spark330/
+Filename: org/apache/spark/sql/spark330/
 Comment: 
 
-Filename: org/apache/spark/sql/
+Filename: org/apache/spark/executor/
 Comment: 
 
-Filename: org/apache/spark/sql/spark330/
+Filename: org/apache/spark/executor/spark330/
 Comment: 
 
 Filename: com/
 Comment: 
 
 Filename: com/intel/
 Comment: 
@@ -51,38 +51,38 @@
 
 Filename: META-INF/maven/com.intel/
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-spark330/
 Comment: 
 
-Filename: org/apache/spark/spark330/TaskContextUtils.class
-Comment: 
-
 Filename: org/apache/spark/spark330/TaskContextUtils$.class
 Comment: 
 
-Filename: org/apache/spark/executor/spark330/RayDPSpark330ExecutorBackendFactory.class
-Comment: 
-
-Filename: org/apache/spark/executor/RayCoarseGrainedExecutorBackend.class
+Filename: org/apache/spark/spark330/TaskContextUtils.class
 Comment: 
 
 Filename: org/apache/spark/sql/spark330/SparkSqlUtils$.class
 Comment: 
 
 Filename: org/apache/spark/sql/spark330/SparkSqlUtils.class
 Comment: 
 
-Filename: com/intel/raydp/shims/spark330/SparkShimProvider$.class
+Filename: org/apache/spark/executor/spark330/RayDPSpark330ExecutorBackendFactory.class
+Comment: 
+
+Filename: org/apache/spark/executor/RayCoarseGrainedExecutorBackend.class
 Comment: 
 
 Filename: com/intel/raydp/shims/spark330/SparkShimProvider.class
 Comment: 
 
+Filename: com/intel/raydp/shims/spark330/SparkShimProvider$.class
+Comment: 
+
 Filename: com/intel/raydp/shims/spark330/Spark330Shims.class
 Comment: 
 
 Filename: META-INF/services/com.intel.raydp.shims.SparkShimProvider
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-spark330/pom.xml
```

### com/intel/raydp/shims/spark330/SparkShimProvider$.class

#### procyon -ec {}

```diff
@@ -9,14 +9,15 @@
 
 public final class SparkShimProvider$
 {
     public static SparkShimProvider$ MODULE$;
     private final SparkShimDescriptor SPARK330_DESCRIPTOR;
     private final SparkShimDescriptor SPARK331_DESCRIPTOR;
     private final SparkShimDescriptor SPARK332_DESCRIPTOR;
+    private final SparkShimDescriptor SPARK333_DESCRIPTOR;
     private final Seq<String> DESCRIPTOR_STRINGS;
     private final SparkShimDescriptor DESCRIPTOR;
     
     static {
         new SparkShimProvider$();
     }
     
@@ -28,24 +29,29 @@
         return this.SPARK331_DESCRIPTOR;
     }
     
     public SparkShimDescriptor SPARK332_DESCRIPTOR() {
         return this.SPARK332_DESCRIPTOR;
     }
     
+    public SparkShimDescriptor SPARK333_DESCRIPTOR() {
+        return this.SPARK333_DESCRIPTOR;
+    }
+    
     public Seq<String> DESCRIPTOR_STRINGS() {
         return this.DESCRIPTOR_STRINGS;
     }
     
     public SparkShimDescriptor DESCRIPTOR() {
         return this.DESCRIPTOR;
     }
     
     private SparkShimProvider$() {
         SparkShimProvider$.MODULE$ = this;
         this.SPARK330_DESCRIPTOR = new SparkShimDescriptor(3, 3, 0);
         this.SPARK331_DESCRIPTOR = new SparkShimDescriptor(3, 3, 1);
         this.SPARK332_DESCRIPTOR = new SparkShimDescriptor(3, 3, 2);
-        this.DESCRIPTOR_STRINGS = (Seq<String>)new $colon$colon((Object)String.valueOf(this.SPARK330_DESCRIPTOR()), (List)new $colon$colon((Object)String.valueOf(this.SPARK331_DESCRIPTOR()), (List)new $colon$colon((Object)String.valueOf(this.SPARK332_DESCRIPTOR()), (List)Nil$.MODULE$)));
+        this.SPARK333_DESCRIPTOR = new SparkShimDescriptor(3, 3, 3);
+        this.DESCRIPTOR_STRINGS = (Seq<String>)new $colon$colon((Object)String.valueOf(this.SPARK330_DESCRIPTOR()), (List)new $colon$colon((Object)String.valueOf(this.SPARK331_DESCRIPTOR()), (List)new $colon$colon((Object)String.valueOf(this.SPARK332_DESCRIPTOR()), (List)new $colon$colon((Object)String.valueOf(this.SPARK333_DESCRIPTOR()), (List)Nil$.MODULE$))));
         this.DESCRIPTOR = this.SPARK332_DESCRIPTOR();
     }
 }
```

### com/intel/raydp/shims/spark330/SparkShimProvider.class

#### procyon -ec {}

```diff
@@ -2,25 +2,29 @@
 package com.intel.raydp.shims.spark330;
 
 import com.intel.raydp.shims.SparkShims;
 import scala.collection.Seq;
 import com.intel.raydp.shims.SparkShimDescriptor;
 import scala.reflect.ScalaSignature;
 
-@ScalaSignature(bytes = "\u0006\u0001m;Q!\u0005\n\t\u0002u1Qa\b\n\t\u0002\u0001BQaJ\u0001\u0005\u0002!Bq!K\u0001C\u0002\u0013\u0005!\u0006\u0003\u00040\u0003\u0001\u0006Ia\u000b\u0005\ba\u0005\u0011\r\u0011\"\u0001+\u0011\u0019\t\u0014\u0001)A\u0005W!9!'\u0001b\u0001\n\u0003Q\u0003BB\u001a\u0002A\u0003%1\u0006C\u00045\u0003\t\u0007I\u0011A\u001b\t\r\u001d\u000b\u0001\u0015!\u00037\u0011\u001dA\u0015A1A\u0005\u0002)Ba!S\u0001!\u0002\u0013Yc\u0001B\u0010\u0013\u0001)CQaJ\u0007\u0005\u00025CQaT\u0007\u0005\u0002ACQ\u0001V\u0007\u0005\u0002U\u000b\u0011c\u00159be.\u001c\u0006.[7Qe>4\u0018\u000eZ3s\u0015\t\u0019B#\u0001\u0005ta\u0006\u00148nM\u001a1\u0015\t)b#A\u0003tQ&l7O\u0003\u0002\u00181\u0005)!/Y=ea*\u0011\u0011DG\u0001\u0006S:$X\r\u001c\u0006\u00027\u0005\u00191m\\7\u0004\u0001A\u0011a$A\u0007\u0002%\t\t2\u000b]1sWNC\u0017.\u001c)s_ZLG-\u001a:\u0014\u0005\u0005\t\u0003C\u0001\u0012&\u001b\u0005\u0019#\"\u0001\u0013\u0002\u000bM\u001c\u0017\r\\1\n\u0005\u0019\u001a#AB!osJ+g-\u0001\u0004=S:LGO\u0010\u000b\u0002;\u0005\u00192\u000bU!S\u0017N\u001a\u0004g\u0018#F'\u000e\u0013\u0016\n\u0015+P%V\t1\u0006\u0005\u0002-[5\tA#\u0003\u0002/)\t\u00192\u000b]1sWNC\u0017.\u001c#fg\u000e\u0014\u0018\u000e\u001d;pe\u0006!2\u000bU!S\u0017N\u001a\u0004g\u0018#F'\u000e\u0013\u0016\n\u0015+P%\u0002\n1c\u0015)B%.\u001b4'M0E\u000bN\u001b%+\u0013)U\u001fJ\u000bAc\u0015)B%.\u001b4'M0E\u000bN\u001b%+\u0013)U\u001fJ\u0003\u0013aE*Q\u0003J[5g\r\u001a`\t\u0016\u001b6IU%Q)>\u0013\u0016\u0001F*Q\u0003J[5g\r\u001a`\t\u0016\u001b6IU%Q)>\u0013\u0006%\u0001\nE\u000bN\u001b%+\u0013)U\u001fJ{6\u000b\u0016*J\u001d\u001e\u001bV#\u0001\u001c\u0011\u0007]RD(D\u00019\u0015\tI4%\u0001\u0006d_2dWm\u0019;j_:L!a\u000f\u001d\u0003\u0007M+\u0017\u000f\u0005\u0002>\t:\u0011aH\u0011\t\u0003\u007f\rj\u0011\u0001\u0011\u0006\u0003\u0003r\ta\u0001\u0010:p_Rt\u0014BA\"$\u0003\u0019\u0001&/\u001a3fM&\u0011QI\u0012\u0002\u0007'R\u0014\u0018N\\4\u000b\u0005\r\u001b\u0013a\u0005#F'\u000e\u0013\u0016\n\u0015+P%~\u001bFKU%O\u000fN\u0003\u0013A\u0003#F'\u000e\u0013\u0016\n\u0015+P%\u0006YA)R*D%&\u0003Fk\u0014*!'\ri\u0011e\u0013\t\u0003Y1K!a\b\u000b\u0015\u00039\u0003\"AH\u0007\u0002\u0015\r\u0014X-\u0019;f'\"LW.F\u0001R!\ta#+\u0003\u0002T)\tQ1\u000b]1sWNC\u0017.\\:\u0002\u000f5\fGo\u00195fgR\u0011a+\u0017\t\u0003E]K!\u0001W\u0012\u0003\u000f\t{w\u000e\\3b]\")!\f\u0005a\u0001y\u00059a/\u001a:tS>t\u0007")
+@ScalaSignature(bytes = "\u0006\u0001};Qa\u0005\u000b\t\u0002}1Q!\t\u000b\t\u0002\tBQ!K\u0001\u0005\u0002)BqaK\u0001C\u0002\u0013\u0005A\u0006\u0003\u00042\u0003\u0001\u0006I!\f\u0005\be\u0005\u0011\r\u0011\"\u0001-\u0011\u0019\u0019\u0014\u0001)A\u0005[!9A'\u0001b\u0001\n\u0003a\u0003BB\u001b\u0002A\u0003%Q\u0006C\u00047\u0003\t\u0007I\u0011\u0001\u0017\t\r]\n\u0001\u0015!\u0003.\u0011\u001dA\u0014A1A\u0005\u0002eBaaS\u0001!\u0002\u0013Q\u0004b\u0002'\u0002\u0005\u0004%\t\u0001\f\u0005\u0007\u001b\u0006\u0001\u000b\u0011B\u0017\u0007\t\u0005\"\u0002A\u0014\u0005\u0006S=!\t!\u0015\u0005\u0006'>!\t\u0001\u0016\u0005\u00061>!\t!W\u0001\u0012'B\f'o[*iS6\u0004&o\u001c<jI\u0016\u0014(BA\u000b\u0017\u0003!\u0019\b/\u0019:lgM\u0002$BA\f\u0019\u0003\u0015\u0019\b.[7t\u0015\tI\"$A\u0003sCf$\u0007O\u0003\u0002\u001c9\u0005)\u0011N\u001c;fY*\tQ$A\u0002d_6\u001c\u0001\u0001\u0005\u0002!\u00035\tACA\tTa\u0006\u00148n\u00155j[B\u0013xN^5eKJ\u001c\"!A\u0012\u0011\u0005\u0011:S\"A\u0013\u000b\u0003\u0019\nQa]2bY\u0006L!\u0001K\u0013\u0003\r\u0005s\u0017PU3g\u0003\u0019a\u0014N\\5u}Q\tq$A\nT!\u0006\u00136jM\u001a1?\u0012+5k\u0011*J!R{%+F\u0001.!\tqs&D\u0001\u0017\u0013\t\u0001dCA\nTa\u0006\u00148n\u00155j[\u0012+7o\u0019:jaR|'/\u0001\u000bT!\u0006\u00136jM\u001a1?\u0012+5k\u0011*J!R{%\u000bI\u0001\u0014'B\u000b%kS\u001a4c}#UiU\"S\u0013B#vJU\u0001\u0015'B\u000b%kS\u001a4c}#UiU\"S\u0013B#vJ\u0015\u0011\u0002'M\u0003\u0016IU&4gIzF)R*D%&\u0003Fk\u0014*\u0002)M\u0003\u0016IU&4gIzF)R*D%&\u0003Fk\u0014*!\u0003M\u0019\u0006+\u0011*LgM\u001at\fR#T\u0007JK\u0005\u000bV(S\u0003Q\u0019\u0006+\u0011*LgM\u001at\fR#T\u0007JK\u0005\u000bV(SA\u0005\u0011B)R*D%&\u0003Fk\u0014*`'R\u0013\u0016JT$T+\u0005Q\u0004cA\u001e?\u00016\tAH\u0003\u0002>K\u0005Q1m\u001c7mK\u000e$\u0018n\u001c8\n\u0005}b$aA*fcB\u0011\u0011\t\u0013\b\u0003\u0005\u001a\u0003\"aQ\u0013\u000e\u0003\u0011S!!\u0012\u0010\u0002\rq\u0012xn\u001c;?\u0013\t9U%\u0001\u0004Qe\u0016$WMZ\u0005\u0003\u0013*\u0013aa\u0015;sS:<'BA$&\u0003M!UiU\"S\u0013B#vJU0T)JKejR*!\u0003)!UiU\"S\u0013B#vJU\u0001\f\t\u0016\u001b6IU%Q)>\u0013\u0006eE\u0002\u0010G=\u0003\"A\f)\n\u0005\u00052B#\u0001*\u0011\u0005\u0001z\u0011AC2sK\u0006$Xm\u00155j[V\tQ\u000b\u0005\u0002/-&\u0011qK\u0006\u0002\u000b'B\f'o[*iS6\u001c\u0018aB7bi\u000eDWm\u001d\u000b\u00035v\u0003\"\u0001J.\n\u0005q+#a\u0002\"p_2,\u0017M\u001c\u0005\u0006=J\u0001\r\u0001Q\u0001\bm\u0016\u00148/[8o\u0001")
 public class SparkShimProvider implements com.intel.raydp.shims.SparkShimProvider
 {
     public static SparkShimDescriptor DESCRIPTOR() {
         return SparkShimProvider$.MODULE$.DESCRIPTOR();
     }
     
     public static Seq<String> DESCRIPTOR_STRINGS() {
         return (Seq<String>)SparkShimProvider$.MODULE$.DESCRIPTOR_STRINGS();
     }
     
+    public static SparkShimDescriptor SPARK333_DESCRIPTOR() {
+        return SparkShimProvider$.MODULE$.SPARK333_DESCRIPTOR();
+    }
+    
     public static SparkShimDescriptor SPARK332_DESCRIPTOR() {
         return SparkShimProvider$.MODULE$.SPARK332_DESCRIPTOR();
     }
     
     public static SparkShimDescriptor SPARK331_DESCRIPTOR() {
         return SparkShimProvider$.MODULE$.SPARK331_DESCRIPTOR();
     }
```

## raydp/jars/raydp-shims-spark340-1.7.0-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,33 +1,33 @@
-Zip file size: 16004 bytes, number of entries: 31
--rw-r--r--  2.0 unx       82 b- defN 23-Sep-19 00:48 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 META-INF/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 org/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 org/apache/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 org/apache/spark/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 org/apache/spark/executor/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 org/apache/spark/executor/spark340/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 org/apache/spark/sql/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 org/apache/spark/sql/spark340/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 org/apache/spark/spark340/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 com/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 com/intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 com/intel/raydp/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 com/intel/raydp/shims/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 com/intel/raydp/shims/spark340/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:47 META-INF/services/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 META-INF/maven/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 META-INF/maven/com.intel/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Sep-19 00:48 META-INF/maven/com.intel/raydp-shims-spark340/
--rw-r--r--  2.0 unx     2841 b- defN 23-Sep-19 00:48 org/apache/spark/executor/RayCoarseGrainedExecutorBackend.class
--rw-r--r--  2.0 unx     2931 b- defN 23-Sep-19 00:48 org/apache/spark/executor/spark340/RayDPSpark340ExecutorBackendFactory.class
--rw-r--r--  2.0 unx     4275 b- defN 23-Sep-19 00:48 org/apache/spark/sql/spark340/SparkSqlUtils$.class
--rw-r--r--  2.0 unx     1344 b- defN 23-Sep-19 00:48 org/apache/spark/sql/spark340/SparkSqlUtils.class
--rw-r--r--  2.0 unx      875 b- defN 23-Sep-19 00:48 org/apache/spark/spark340/TaskContextUtils.class
--rw-r--r--  2.0 unx     1628 b- defN 23-Sep-19 00:48 org/apache/spark/spark340/TaskContextUtils$.class
--rw-r--r--  2.0 unx     1485 b- defN 23-Sep-19 00:48 com/intel/raydp/shims/spark340/SparkShimProvider$.class
--rw-r--r--  2.0 unx     2994 b- defN 23-Sep-19 00:48 com/intel/raydp/shims/spark340/Spark340Shims.class
--rw-r--r--  2.0 unx     2078 b- defN 23-Sep-19 00:48 com/intel/raydp/shims/spark340/SparkShimProvider.class
--rw-r--r--  2.0 unx       49 b- defN 23-Sep-19 00:47 META-INF/services/com.intel.raydp.shims.SparkShimProvider
--rw-r--r--  2.0 unx     2936 b- defN 23-Sep-19 00:46 META-INF/maven/com.intel/raydp-shims-spark340/pom.xml
--rw-r--r--  2.0 unx       73 b- defN 23-Sep-19 00:48 META-INF/maven/com.intel/raydp-shims-spark340/pom.properties
-31 files, 23591 bytes uncompressed, 11526 bytes compressed:  51.1%
+Zip file size: 16185 bytes, number of entries: 31
+-rw-r--r--  2.0 unx       82 b- defN 24-Apr-10 00:48 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/sql/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/sql/spark340/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/executor/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/executor/spark340/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 org/apache/spark/spark340/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/shims/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 com/intel/raydp/shims/spark340/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/services/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-shims-spark340/
+-rw-r--r--  2.0 unx     4275 b- defN 24-Apr-10 00:48 org/apache/spark/sql/spark340/SparkSqlUtils$.class
+-rw-r--r--  2.0 unx     1344 b- defN 24-Apr-10 00:48 org/apache/spark/sql/spark340/SparkSqlUtils.class
+-rw-r--r--  2.0 unx     2841 b- defN 24-Apr-10 00:48 org/apache/spark/executor/RayCoarseGrainedExecutorBackend.class
+-rw-r--r--  2.0 unx     2931 b- defN 24-Apr-10 00:48 org/apache/spark/executor/spark340/RayDPSpark340ExecutorBackendFactory.class
+-rw-r--r--  2.0 unx     1628 b- defN 24-Apr-10 00:48 org/apache/spark/spark340/TaskContextUtils$.class
+-rw-r--r--  2.0 unx      875 b- defN 24-Apr-10 00:48 org/apache/spark/spark340/TaskContextUtils.class
+-rw-r--r--  2.0 unx     2345 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark340/SparkShimProvider.class
+-rw-r--r--  2.0 unx     1781 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark340/SparkShimProvider$.class
+-rw-r--r--  2.0 unx     2994 b- defN 24-Apr-10 00:48 com/intel/raydp/shims/spark340/Spark340Shims.class
+-rw-r--r--  2.0 unx       49 b- defN 24-Apr-10 00:48 META-INF/services/com.intel.raydp.shims.SparkShimProvider
+-rw-r--r--  2.0 unx     2936 b- defN 24-Apr-10 00:47 META-INF/maven/com.intel/raydp-shims-spark340/pom.xml
+-rw-r--r--  2.0 unx       73 b- defN 24-Apr-10 00:48 META-INF/maven/com.intel/raydp-shims-spark340/pom.properties
+31 files, 24154 bytes uncompressed, 11707 bytes compressed:  51.5%
```

### zipnote «TEMP»/diffoscope_1d0ljn3y_/tmp0ylc5teo_.zip

```diff
@@ -9,24 +9,24 @@
 
 Filename: org/apache/
 Comment: 
 
 Filename: org/apache/spark/
 Comment: 
 
-Filename: org/apache/spark/executor/
+Filename: org/apache/spark/sql/
 Comment: 
 
-Filename: org/apache/spark/executor/spark340/
+Filename: org/apache/spark/sql/spark340/
 Comment: 
 
-Filename: org/apache/spark/sql/
+Filename: org/apache/spark/executor/
 Comment: 
 
-Filename: org/apache/spark/sql/spark340/
+Filename: org/apache/spark/executor/spark340/
 Comment: 
 
 Filename: org/apache/spark/spark340/
 Comment: 
 
 Filename: com/
 Comment: 
@@ -51,41 +51,41 @@
 
 Filename: META-INF/maven/com.intel/
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-spark340/
 Comment: 
 
-Filename: org/apache/spark/executor/RayCoarseGrainedExecutorBackend.class
+Filename: org/apache/spark/sql/spark340/SparkSqlUtils$.class
 Comment: 
 
-Filename: org/apache/spark/executor/spark340/RayDPSpark340ExecutorBackendFactory.class
+Filename: org/apache/spark/sql/spark340/SparkSqlUtils.class
 Comment: 
 
-Filename: org/apache/spark/sql/spark340/SparkSqlUtils$.class
+Filename: org/apache/spark/executor/RayCoarseGrainedExecutorBackend.class
 Comment: 
 
-Filename: org/apache/spark/sql/spark340/SparkSqlUtils.class
+Filename: org/apache/spark/executor/spark340/RayDPSpark340ExecutorBackendFactory.class
+Comment: 
+
+Filename: org/apache/spark/spark340/TaskContextUtils$.class
 Comment: 
 
 Filename: org/apache/spark/spark340/TaskContextUtils.class
 Comment: 
 
-Filename: org/apache/spark/spark340/TaskContextUtils$.class
+Filename: com/intel/raydp/shims/spark340/SparkShimProvider.class
 Comment: 
 
 Filename: com/intel/raydp/shims/spark340/SparkShimProvider$.class
 Comment: 
 
 Filename: com/intel/raydp/shims/spark340/Spark340Shims.class
 Comment: 
 
-Filename: com/intel/raydp/shims/spark340/SparkShimProvider.class
-Comment: 
-
 Filename: META-INF/services/com.intel.raydp.shims.SparkShimProvider
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-spark340/pom.xml
 Comment: 
 
 Filename: META-INF/maven/com.intel/raydp-shims-spark340/pom.properties
```

### com/intel/raydp/shims/spark340/SparkShimProvider$.class

#### procyon -ec {}

```diff
@@ -7,33 +7,45 @@
 import scala.collection.Seq;
 import com.intel.raydp.shims.SparkShimDescriptor;
 
 public final class SparkShimProvider$
 {
     public static SparkShimProvider$ MODULE$;
     private final SparkShimDescriptor SPARK340_DESCRIPTOR;
+    private final SparkShimDescriptor SPARK341_DESCRIPTOR;
+    private final SparkShimDescriptor SPARK342_DESCRIPTOR;
     private final Seq<String> DESCRIPTOR_STRINGS;
     private final SparkShimDescriptor DESCRIPTOR;
     
     static {
         new SparkShimProvider$();
     }
     
     public SparkShimDescriptor SPARK340_DESCRIPTOR() {
         return this.SPARK340_DESCRIPTOR;
     }
     
+    public SparkShimDescriptor SPARK341_DESCRIPTOR() {
+        return this.SPARK341_DESCRIPTOR;
+    }
+    
+    public SparkShimDescriptor SPARK342_DESCRIPTOR() {
+        return this.SPARK342_DESCRIPTOR;
+    }
+    
     public Seq<String> DESCRIPTOR_STRINGS() {
         return this.DESCRIPTOR_STRINGS;
     }
     
     public SparkShimDescriptor DESCRIPTOR() {
         return this.DESCRIPTOR;
     }
     
     private SparkShimProvider$() {
         SparkShimProvider$.MODULE$ = this;
         this.SPARK340_DESCRIPTOR = new SparkShimDescriptor(3, 4, 0);
-        this.DESCRIPTOR_STRINGS = (Seq<String>)new $colon$colon((Object)String.valueOf(this.SPARK340_DESCRIPTOR()), (List)Nil$.MODULE$);
-        this.DESCRIPTOR = this.SPARK340_DESCRIPTOR();
+        this.SPARK341_DESCRIPTOR = new SparkShimDescriptor(3, 4, 1);
+        this.SPARK342_DESCRIPTOR = new SparkShimDescriptor(3, 4, 2);
+        this.DESCRIPTOR_STRINGS = (Seq<String>)new $colon$colon((Object)String.valueOf(this.SPARK340_DESCRIPTOR()), (List)new $colon$colon((Object)String.valueOf(this.SPARK341_DESCRIPTOR()), (List)new $colon$colon((Object)String.valueOf(this.SPARK342_DESCRIPTOR()), (List)Nil$.MODULE$)));
+        this.DESCRIPTOR = this.SPARK341_DESCRIPTOR();
     }
 }
```

### com/intel/raydp/shims/spark340/SparkShimProvider.class

#### procyon -ec {}

```diff
@@ -2,25 +2,33 @@
 package com.intel.raydp.shims.spark340;
 
 import com.intel.raydp.shims.SparkShims;
 import scala.collection.Seq;
 import com.intel.raydp.shims.SparkShimDescriptor;
 import scala.reflect.ScalaSignature;
 
-@ScalaSignature(bytes = "\u0006\u0001M;Q!\u0004\b\t\u0002e1Qa\u0007\b\t\u0002qAQaI\u0001\u0005\u0002\u0011Bq!J\u0001C\u0002\u0013\u0005a\u0005\u0003\u0004,\u0003\u0001\u0006Ia\n\u0005\bY\u0005\u0011\r\u0011\"\u0001.\u0011\u0019y\u0014\u0001)A\u0005]!9\u0001)\u0001b\u0001\n\u00031\u0003BB!\u0002A\u0003%qE\u0002\u0003\u001c\u001d\u0001\u0011\u0005\"B\u0012\n\t\u0003)\u0005\"B$\n\t\u0003A\u0005\"\u0002'\n\t\u0003i\u0015!E*qCJ\\7\u000b[5n!J|g/\u001b3fe*\u0011q\u0002E\u0001\tgB\f'o[\u001a5a)\u0011\u0011CE\u0001\u0006g\"LWn\u001d\u0006\u0003'Q\tQA]1zIBT!!\u0006\f\u0002\u000b%tG/\u001a7\u000b\u0003]\t1aY8n\u0007\u0001\u0001\"AG\u0001\u000e\u00039\u0011\u0011c\u00159be.\u001c\u0006.[7Qe>4\u0018\u000eZ3s'\t\tQ\u0004\u0005\u0002\u001fC5\tqDC\u0001!\u0003\u0015\u00198-\u00197b\u0013\t\u0011sD\u0001\u0004B]f\u0014VMZ\u0001\u0007y%t\u0017\u000e\u001e \u0015\u0003e\t1c\u0015)B%.\u001bD\u0007M0E\u000bN\u001b%+\u0013)U\u001fJ+\u0012a\n\t\u0003Q%j\u0011\u0001E\u0005\u0003UA\u00111c\u00159be.\u001c\u0006.[7EKN\u001c'/\u001b9u_J\fAc\u0015)B%.\u001bD\u0007M0E\u000bN\u001b%+\u0013)U\u001fJ\u0003\u0013A\u0005#F'\u000e\u0013\u0016\n\u0015+P%~\u001bFKU%O\u000fN+\u0012A\f\t\u0004_I\"T\"\u0001\u0019\u000b\u0005Ez\u0012AC2pY2,7\r^5p]&\u00111\u0007\r\u0002\u0004'\u0016\f\bCA\u001b=\u001d\t1$\b\u0005\u00028?5\t\u0001H\u0003\u0002:1\u00051AH]8pizJ!aO\u0010\u0002\rA\u0013X\rZ3g\u0013\tidH\u0001\u0004TiJLgn\u001a\u0006\u0003w}\t1\u0003R#T\u0007JK\u0005\u000bV(S?N#&+\u0013(H'\u0002\n!\u0002R#T\u0007JK\u0005\u000bV(S\u0003-!UiU\"S\u0013B#vJ\u0015\u0011\u0014\u0007%i2\t\u0005\u0002)\t&\u00111\u0004\u0005\u000b\u0002\rB\u0011!$C\u0001\u000bGJ,\u0017\r^3TQ&lW#A%\u0011\u0005!R\u0015BA&\u0011\u0005)\u0019\u0006/\u0019:l'\"LWn]\u0001\b[\u0006$8\r[3t)\tq\u0015\u000b\u0005\u0002\u001f\u001f&\u0011\u0001k\b\u0002\b\u0005>|G.Z1o\u0011\u0015\u0011F\u00021\u00015\u0003\u001d1XM]:j_:\u0004")
+@ScalaSignature(bytes = "\u0006\u0001m;Q!\u0005\n\t\u0002u1Qa\b\n\t\u0002\u0001BQaJ\u0001\u0005\u0002!Bq!K\u0001C\u0002\u0013\u0005!\u0006\u0003\u00040\u0003\u0001\u0006Ia\u000b\u0005\ba\u0005\u0011\r\u0011\"\u0001+\u0011\u0019\t\u0014\u0001)A\u0005W!9!'\u0001b\u0001\n\u0003Q\u0003BB\u001a\u0002A\u0003%1\u0006C\u00045\u0003\t\u0007I\u0011A\u001b\t\r\u001d\u000b\u0001\u0015!\u00037\u0011\u001dA\u0015A1A\u0005\u0002)Ba!S\u0001!\u0002\u0013Yc\u0001B\u0010\u0013\u0001)CQaJ\u0007\u0005\u00025CQaT\u0007\u0005\u0002ACQ\u0001V\u0007\u0005\u0002U\u000b\u0011c\u00159be.\u001c\u0006.[7Qe>4\u0018\u000eZ3s\u0015\t\u0019B#\u0001\u0005ta\u0006\u00148n\r\u001b1\u0015\t)b#A\u0003tQ&l7O\u0003\u0002\u00181\u0005)!/Y=ea*\u0011\u0011DG\u0001\u0006S:$X\r\u001c\u0006\u00027\u0005\u00191m\\7\u0004\u0001A\u0011a$A\u0007\u0002%\t\t2\u000b]1sWNC\u0017.\u001c)s_ZLG-\u001a:\u0014\u0005\u0005\t\u0003C\u0001\u0012&\u001b\u0005\u0019#\"\u0001\u0013\u0002\u000bM\u001c\u0017\r\\1\n\u0005\u0019\u001a#AB!osJ+g-\u0001\u0004=S:LGO\u0010\u000b\u0002;\u0005\u00192\u000bU!S\u0017N\"\u0004g\u0018#F'\u000e\u0013\u0016\n\u0015+P%V\t1\u0006\u0005\u0002-[5\tA#\u0003\u0002/)\t\u00192\u000b]1sWNC\u0017.\u001c#fg\u000e\u0014\u0018\u000e\u001d;pe\u0006!2\u000bU!S\u0017N\"\u0004g\u0018#F'\u000e\u0013\u0016\n\u0015+P%\u0002\n1c\u0015)B%.\u001bD'M0E\u000bN\u001b%+\u0013)U\u001fJ\u000bAc\u0015)B%.\u001bD'M0E\u000bN\u001b%+\u0013)U\u001fJ\u0003\u0013aE*Q\u0003J[5\u0007\u000e\u001a`\t\u0016\u001b6IU%Q)>\u0013\u0016\u0001F*Q\u0003J[5\u0007\u000e\u001a`\t\u0016\u001b6IU%Q)>\u0013\u0006%\u0001\nE\u000bN\u001b%+\u0013)U\u001fJ{6\u000b\u0016*J\u001d\u001e\u001bV#\u0001\u001c\u0011\u0007]RD(D\u00019\u0015\tI4%\u0001\u0006d_2dWm\u0019;j_:L!a\u000f\u001d\u0003\u0007M+\u0017\u000f\u0005\u0002>\t:\u0011aH\u0011\t\u0003\u007f\rj\u0011\u0001\u0011\u0006\u0003\u0003r\ta\u0001\u0010:p_Rt\u0014BA\"$\u0003\u0019\u0001&/\u001a3fM&\u0011QI\u0012\u0002\u0007'R\u0014\u0018N\\4\u000b\u0005\r\u001b\u0013a\u0005#F'\u000e\u0013\u0016\n\u0015+P%~\u001bFKU%O\u000fN\u0003\u0013A\u0003#F'\u000e\u0013\u0016\n\u0015+P%\u0006YA)R*D%&\u0003Fk\u0014*!'\ri\u0011e\u0013\t\u0003Y1K!a\b\u000b\u0015\u00039\u0003\"AH\u0007\u0002\u0015\r\u0014X-\u0019;f'\"LW.F\u0001R!\ta#+\u0003\u0002T)\tQ1\u000b]1sWNC\u0017.\\:\u0002\u000f5\fGo\u00195fgR\u0011a+\u0017\t\u0003E]K!\u0001W\u0012\u0003\u000f\t{w\u000e\\3b]\")!\f\u0005a\u0001y\u00059a/\u001a:tS>t\u0007")
 public class SparkShimProvider implements com.intel.raydp.shims.SparkShimProvider
 {
     public static SparkShimDescriptor DESCRIPTOR() {
         return SparkShimProvider$.MODULE$.DESCRIPTOR();
     }
     
     public static Seq<String> DESCRIPTOR_STRINGS() {
         return (Seq<String>)SparkShimProvider$.MODULE$.DESCRIPTOR_STRINGS();
     }
     
+    public static SparkShimDescriptor SPARK342_DESCRIPTOR() {
+        return SparkShimProvider$.MODULE$.SPARK342_DESCRIPTOR();
+    }
+    
+    public static SparkShimDescriptor SPARK341_DESCRIPTOR() {
+        return SparkShimProvider$.MODULE$.SPARK341_DESCRIPTOR();
+    }
+    
     public static SparkShimDescriptor SPARK340_DESCRIPTOR() {
         return SparkShimProvider$.MODULE$.SPARK340_DESCRIPTOR();
     }
     
     public SparkShims createShim() {
         return (SparkShims)new Spark340Shims();
     }
```

## raydp/spark/__init__.py

```diff
@@ -11,23 +11,27 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 
-from .dataset import spark_dataframe_to_ray_dataset, \
+from .dataset import PartitionObjectsOwner, \
+                     get_raydp_master_owner, \
+                     spark_dataframe_to_ray_dataset, \
                      ray_dataset_to_spark_dataframe, \
                      from_spark_recoverable
 from .interfaces import SparkEstimatorInterface
 from .ray_cluster import SparkCluster
 
 __all__ = [
   "SparkCluster",
   "SparkEstimatorInterface",
+  "PartitionObjectsOwner",
+  "get_raydp_master_owner",
   "spark_dataframe_to_ray_dataset",
   "ray_dataset_to_spark_dataframe",
   "from_spark_recoverable"
 ]
 
 try:
     import ray.util.data
```

## raydp/spark/dataset.py

```diff
@@ -9,24 +9,25 @@
 #    http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
 import logging
 import uuid
 from typing import Callable, Dict, List, NoReturn, Optional, Iterable, Union
+from dataclasses import dataclass
 
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 import pyarrow.parquet as pq
 import pyspark.sql as sql
+from pyspark.sql import SparkSession
 from pyspark.sql.dataframe import DataFrame
 from pyspark.sql.types import StructType
 from pyspark.sql.pandas.types import from_arrow_type
 from pyspark.storagelevel import StorageLevel
 import ray
 from ray.data import Dataset, from_arrow_refs
 from ray.types import ObjectRef
@@ -128,14 +129,38 @@
         if new_row_ids:
             num_rows = len(new_row_ids)
         else:
             num_rows = self.num_rows
         return ParquetPiece(self.piece, self.columns, self.partitions, new_row_ids, num_rows)
 
 
+@dataclass
+class PartitionObjectsOwner:
+    # Actor owner name
+    actor_name: str
+    # Function that set serialized parquet objects to actor owner state
+    # and return result of .remote() calling
+    set_reference_as_state: Callable[[ray.actor.ActorHandle, List[ObjectRef]], ObjectRef]
+
+
+def get_raydp_master_owner(spark: Optional[SparkSession] = None) -> PartitionObjectsOwner:
+    if spark is None:
+        spark = SparkSession.getActiveSession()
+    obj_holder_name = spark.sparkContext.appName + RAYDP_SPARK_MASTER_SUFFIX
+
+    def raydp_master_set_reference_as_state(
+            raydp_master_actor: ray.actor.ActorHandle,
+            objects: List[ObjectRef]) -> ObjectRef:
+        return raydp_master_actor.add_objects.remote(uuid.uuid4(), objects)
+
+    return PartitionObjectsOwner(
+        obj_holder_name,
+        raydp_master_set_reference_as_state)
+
+
 @client_mode_wrap
 def _register_objects(records):
     worker = ray.worker.global_worker
     blocks: List[ray.ObjectRef] = []
     block_sizes: List[int] = []
     for obj_id, owner, num_record in records:
         object_ref = ray.ObjectRef(obj_id)
@@ -143,44 +168,42 @@
         worker.core_worker.deserialize_and_register_object_ref(
             object_ref.binary(), ray.ObjectRef.nil(), owner, "")
         blocks.append(object_ref)
         block_sizes.append(num_record)
     return blocks, block_sizes
 
 def _save_spark_df_to_object_store(df: sql.DataFrame, use_batch: bool = True,
-                                   _use_owner: bool = False):
+                                   owner: Union[PartitionObjectsOwner, None] = None):
     # call java function from python
     jvm = df.sql_ctx.sparkSession.sparkContext._jvm
     jdf = df._jdf
     object_store_writer = jvm.org.apache.spark.sql.raydp.ObjectStoreWriter(jdf)
-    obj_holder_name = df.sql_ctx.sparkSession.sparkContext.appName + RAYDP_SPARK_MASTER_SUFFIX
-    if _use_owner is True:
-        records = object_store_writer.save(use_batch, obj_holder_name)
-    else:
-        records = object_store_writer.save(use_batch, "")
+    actor_owner_name = ""
+    if owner is not None:
+        actor_owner_name = owner.actor_name
+    records = object_store_writer.save(use_batch, actor_owner_name)
 
     record_tuples = [(record.objectId(), record.ownerAddress(), record.numRecords())
-                        for record in records]
+                     for record in records]
     blocks, block_sizes = _register_objects(record_tuples)
 
-    if _use_owner is True:
-        holder = ray.get_actor(obj_holder_name)
-        df_id = uuid.uuid4()
-        ray.get(holder.add_objects.remote(df_id, blocks))
+    if owner is not None:
+        actor_owner = ray.get_actor(actor_owner_name)
+        ray.get(owner.set_reference_as_state(actor_owner, blocks))
 
     return blocks, block_sizes
 
 def spark_dataframe_to_ray_dataset(df: sql.DataFrame,
                                    parallelism: Optional[int] = None,
-                                   _use_owner: bool = False):
+                                   owner: Union[PartitionObjectsOwner, None] = None):
     num_part = df.rdd.getNumPartitions()
     if parallelism is not None:
         if parallelism != num_part:
             df = df.repartition(parallelism)
-    blocks, _ = _save_spark_df_to_object_store(df, False, _use_owner)
+    blocks, _ = _save_spark_df_to_object_store(df, False, owner)
     return from_arrow_refs(blocks)
 
 # This is an experimental API for now.
 # If you had any issue using it, welcome to report at our github.
 # This function WILL cache/persist the dataframe!
 def from_spark_recoverable(df: sql.DataFrame,
                            storage_level: StorageLevel = StorageLevel.MEMORY_AND_DISK,
```

## raydp/tf/estimator.py

```diff
@@ -18,25 +18,24 @@
 from typing import Any, List, NoReturn, Optional, Union, Dict
 
 import tensorflow as tf
 import tensorflow.keras as keras
 from tensorflow import DType, TensorShape
 from tensorflow.keras.callbacks import Callback
 
-from ray.train.tensorflow import TensorflowTrainer, prepare_dataset_shard
+from ray.train.tensorflow import TensorflowTrainer, TensorflowCheckpoint, prepare_dataset_shard
 from ray.air import session
 from ray.air.config import ScalingConfig, RunConfig, FailureConfig
-from ray.air.checkpoint import Checkpoint
 from ray.data import read_parquet
 from ray.data.dataset import Dataset
 from ray.data.preprocessors import Concatenator
 from raydp.estimator import EstimatorInterface
 from raydp.spark.interfaces import SparkEstimatorInterface, DF, OPTIONAL_DF
 from raydp import stop_spark
-from raydp.spark import spark_dataframe_to_ray_dataset
+from raydp.spark import spark_dataframe_to_ray_dataset, get_raydp_master_owner
 
 class TFEstimator(EstimatorInterface, SparkEstimatorInterface):
     def __init__(self,
                  num_workers: int = 1,
                  resources_per_worker: Optional[Dict[str, float]] = None,
                  model: keras.Model = None,
                  optimizer: Union[keras.optimizers.Optimizer, str] = None,
@@ -181,17 +180,15 @@
         callbacks = config["callbacks"]
         for _ in range(config["num_epochs"]):
             train_history = multi_worker_model.fit(train_tf_dataset, callbacks=callbacks)
             results.append(train_history.history)
             if config["evaluate"]:
                 test_history = multi_worker_model.evaluate(eval_tf_dataset, callbacks=callbacks)
                 results.append(test_history)
-        session.report({}, checkpoint=Checkpoint.from_dict({
-            "model_weights": multi_worker_model.get_weights()
-        }))
+        session.report({}, checkpoint=TensorflowCheckpoint.from_model(multi_worker_model))
 
     def fit(self,
             train_ds: Dataset,
             evaluate_ds: Optional[Dataset] = None,
             max_retries=0) -> NoReturn:
         # super().fit(train_ds, evaluate_ds)
         train_loop_config = {
@@ -251,23 +248,24 @@
             train_df.write.parquet(path+"/train", compression=compression)
             train_ds = read_parquet(path+"/train")
             if evaluate_df is not None:
                 evaluate_df = self._check_and_convert(evaluate_df)
                 evaluate_df.write.parquet(path+"/test", compression=compression)
                 evaluate_ds = read_parquet(path+"/test")
         else:
+            owner = None
+            if stop_spark_after_conversion:
+                owner = get_raydp_master_owner(train_df.sql_ctx.sparkSession)
             train_ds = spark_dataframe_to_ray_dataset(train_df,
-                                                    _use_owner=stop_spark_after_conversion)
+                                                    owner=owner)
             if evaluate_df is not None:
                 evaluate_df = self._check_and_convert(evaluate_df)
                 evaluate_ds = spark_dataframe_to_ray_dataset(evaluate_df,
-                                                         _use_owner=stop_spark_after_conversion)
+                                                         owner=owner)
         if stop_spark_after_conversion:
             stop_spark(cleanup_data=False)
         return self.fit(
             train_ds, evaluate_ds, max_retries)
 
     def get_model(self) -> Any:
         assert self._trainer, "Trainer has not been created"
-        model = keras.models.model_from_json(self._serialized_model)
-        model.set_weights(self._results.checkpoint.to_dict()["model_weights"])
-        return model
+        return self._results.checkpoint.get_model()
```

## raydp/torch/config.py

```diff
@@ -12,15 +12,23 @@
 @dataclass
 class TorchConfig(RayTorchConfig):
 
     @property
     def backend_cls(self):
         return EnableCCLBackend
 
-def ccl_import():
+def libs_import():
+    """try to import IPEX and oneCCL.
+    """
+    try:
+        import intel_extension_for_pytorch
+    except ImportError:
+        raise ImportError(
+            "Please install intel_extension_for_pytorch"
+        )
     try:
         ccl_version = importlib_metadata.version("oneccl_bind_pt")
         if ccl_version >= "1.12":
             # pylint: disable-all
             import oneccl_bindings_for_pytorch
         else:
             import torch_ccl
@@ -29,9 +37,9 @@
             "Please install torch-ccl"
         ) from ccl_not_exist
 
 class EnableCCLBackend(_TorchBackend):
 
     def on_start(self, worker_group: WorkerGroup, backend_config: RayTorchConfig):
         for i in range(len(worker_group)):
-            worker_group.execute_single_async(i, ccl_import)
+            worker_group.execute_single_async(i, libs_import)
         super().on_start(worker_group, backend_config)
```

## raydp/torch/estimator.py

```diff
@@ -21,22 +21,21 @@
 import torch
 from torch.nn.modules.loss import _Loss as TLoss
 
 from raydp.estimator import EstimatorInterface
 from raydp.spark.interfaces import SparkEstimatorInterface, DF, OPTIONAL_DF
 from raydp.torch.torch_metrics import TorchMetric
 from raydp import stop_spark
-from raydp.spark import spark_dataframe_to_ray_dataset
+from raydp.spark import spark_dataframe_to_ray_dataset, get_raydp_master_owner
 from raydp.torch.config import TorchConfig
 
 import ray
 from ray import train
-from ray.train.torch import TorchTrainer
+from ray.train.torch import TorchTrainer, TorchCheckpoint
 from ray.air.config import ScalingConfig, RunConfig, FailureConfig
-from ray.air.checkpoint import Checkpoint
 from ray.air import session
 from ray.data.dataset import Dataset
 from ray.tune.search.sample import Domain
 
 class TorchEstimator(EstimatorInterface, SparkEstimatorInterface):
     """
     A scikit-learn like API to distributed training torch model. In the backend it leverage
@@ -251,17 +250,15 @@
                 session.report(dict(epoch=epoch, eval_res=eval_res, test_loss=evaluate_loss))
                 loss_results.append(evaluate_loss)
         if hasattr(model, "module"):
             states = model.module.state_dict()
         else:
             # if num_workers = 1, model is not wrapped
             states = model.state_dict()
-        session.report({}, checkpoint=Checkpoint.from_dict({
-            "state_dict": states
-        }))
+        session.report({}, checkpoint=TorchCheckpoint.from_state_dict(states))
 
     @staticmethod
     def train_epoch(dataset, model, criterion, optimizer, metrics, scheduler=None):
         model.train()
         train_loss, data_size, batch_idx = 0, 0, 0
         for batch_idx, (inputs, targets) in enumerate(dataset):
             # Compute prediction error
@@ -361,31 +358,24 @@
             train_df.write.parquet(path+"/train", compression=compression)
             train_ds = ray.data.read_parquet(path+"/train")
             if evaluate_df is not None:
                 evaluate_df = self._check_and_convert(evaluate_df)
                 evaluate_df.write.parquet(path+"/test", compression=compression)
                 evaluate_ds = ray.data.read_parquet(path+"/test")
         else:
+            owner = None
+            if stop_spark_after_conversion:
+                owner = get_raydp_master_owner(train_df.sql_ctx.sparkSession)
             train_ds = spark_dataframe_to_ray_dataset(train_df,
-                                                  _use_owner=stop_spark_after_conversion)
+                                                      owner=owner)
             if evaluate_df is not None:
                 evaluate_df = self._check_and_convert(evaluate_df)
                 evaluate_ds = spark_dataframe_to_ray_dataset(evaluate_df,
-                                                         _use_owner=stop_spark_after_conversion)
+                                                             owner=owner)
         if stop_spark_after_conversion:
             stop_spark(cleanup_data=False)
         return self.fit(
             train_ds, evaluate_ds, max_retries)
 
     def get_model(self):
         assert self._trainer is not None, "Must call fit first"
-        states = self._trained_results.checkpoint.to_dict()["state_dict"]
-        if isinstance(self._model, torch.nn.Module):
-            model = self._model
-        elif callable(self._model):
-            model = self._model()
-        else:
-            raise Exception(
-                "Unsupported parameter, we only support torch.nn.Model instance "
-                "or a function(dict -> model)")
-        model.load_state_dict(states)
-        return model
+        return self._trained_results.checkpoint.get_model()
```

## raydp/xgboost/estimator.py

```diff
@@ -16,15 +16,15 @@
 #
 
 from typing import Any, Callable, List, NoReturn, Optional, Union, Dict
 
 from raydp.estimator import EstimatorInterface
 from raydp.spark.interfaces import SparkEstimatorInterface, DF, OPTIONAL_DF
 from raydp import stop_spark
-from raydp.spark import spark_dataframe_to_ray_dataset
+from raydp.spark import spark_dataframe_to_ray_dataset, get_raydp_master_owner
 
 import ray
 from ray.air.config import ScalingConfig, RunConfig, FailureConfig
 from ray.data.dataset import Dataset
 from ray.train.xgboost import XGBoostTrainer, XGBoostCheckpoint
 
 class XGBoostEstimator(EstimatorInterface, SparkEstimatorInterface):
@@ -95,22 +95,25 @@
             train_df.write.parquet(path+"/train", compression=compression)
             train_ds = ray.data.read_parquet(path+"/train")
             if evaluate_df is not None:
                 evaluate_df = self._check_and_convert(evaluate_df)
                 evaluate_df.write.parquet(path+"/test", compression=compression)
                 evaluate_ds = ray.data.read_parquet(path+"/test")
         else:
+            owner = None
+            if stop_spark_after_conversion:
+                owner = get_raydp_master_owner(train_df.sql_ctx.sparkSession)
             train_ds = spark_dataframe_to_ray_dataset(train_df,
-                                                  parallelism=self._num_workers,
-                                                  _use_owner=stop_spark_after_conversion)
+                                                      parallelism=self._num_workers,
+                                                      owner=owner)
             if evaluate_df is not None:
                 evaluate_df = self._check_and_convert(evaluate_df)
                 evaluate_ds = spark_dataframe_to_ray_dataset(evaluate_df,
-                                                         parallelism=self._num_workers,
-                                                         _use_owner=stop_spark_after_conversion)
+                                                             parallelism=self._num_workers,
+                                                             owner=owner)
         if stop_spark_after_conversion:
             stop_spark(cleanup_data=False)
         return self.fit(
             train_ds, evaluate_ds, max_retries)
 
     def get_model(self):
         return XGBoostCheckpoint.from_checkpoint(self._results.checkpoint).get_model()
```

## Comparing `raydp_nightly-2023.9.19.dev0.dist-info/METADATA` & `raydp_nightly-2024.4.10.dev0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: raydp-nightly
-Version: 2023.9.19.dev0
+Version: 2024.4.10.dev0
 Summary: RayDP: Distributed Data Processing on Ray
 Home-page: https://github.com/oap-project/raydp
 Author: RayDP Developers
 Author-email: raydp-dev@googlegroups.com
 License: Apache 2.0
 Keywords: raydp spark ray distributed data-processing
 Platform: UNKNOWN
@@ -15,15 +15,15 @@
 Requires-Python: >=3.6
 Description-Content-Type: text/markdown
 Requires-Dist: numpy
 Requires-Dist: pandas >=1.1.4
 Requires-Dist: psutil
 Requires-Dist: pyarrow >=4.0.1
 Requires-Dist: ray >=2.1.0
-Requires-Dist: pyspark <=3.3.2,>=3.1.1
+Requires-Dist: pyspark <=3.5.0,>=3.1.1
 Requires-Dist: netifaces
 Requires-Dist: protobuf <=3.20.3,>3.19.5
 
 # [RayDP]()
 RayDP provides simple APIs for running Spark on [Ray](https://github.com/ray-project/ray) and integrating Spark with AI libraries, making it simple to build distributed data and AI pipeline in a single python program.
 
 # INTRODUCTION
```

## Comparing `raydp_nightly-2023.9.19.dev0.dist-info/RECORD` & `raydp_nightly-2024.4.10.dev0.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,41 +1,42 @@
 raydp/__init__.py,sha256=3o9isITemJcehBuMfl60WEs2Rl6tetUR_xZnvJxWLrQ,902
 raydp/context.py,sha256=1Da4q82dCUOP80ZLPx4CREBS-wdU9wZw0rouHqoSkf8,10438
 raydp/estimator.py,sha256=6oC7rr1uW9lLW3QXgyTsbHt2aV5dcvtQB_JqUMBfPzo,1380
 raydp/ray_cluster_resources.py,sha256=LIw95KFW-7zwlQc5BH6_xUILJp8h_iAYXMDp9OX9dFY,2764
 raydp/services.py,sha256=CVhPB0d40cKr6ZikYIMfxujd-By5anYgvKgwy5ip1zI,3007
 raydp/utils.py,sha256=rY6dM5NHgT6zrjWUQTKWLBa8kSuseicQ5FrCX_ngAYI,7666
 raydp/versions.py,sha256=ntYtL0tkRCyD5cFOAiZeJoDwZ16dXyRJtXC3Me7COwU,1474
-raydp/bin/raydp-submit,sha256=YhiUJ-1doxxkEK6NEYPzZmOJsr-Xt1hUAYOeM4aLpc8,5090
-raydp/jars/raydp-1.7.0-SNAPSHOT.jar,sha256=1JBGfempI-WP07vgzrWZOmpNGT7rguk2qdxxb2ll9Wc,286937
-raydp/jars/raydp-agent-1.7.0-SNAPSHOT.jar,sha256=cYMnm4VbbaS599tayA9-ak9Fvvb36PvkXU7vZuDg9Go,7071
-raydp/jars/raydp-shims-common-1.7.0-SNAPSHOT.jar,sha256=qWuQHV4CwsuY-LpTG4IgReBU_JhyCNLlDmUvAHDj6Z4,16000
-raydp/jars/raydp-shims-spark322-1.7.0-SNAPSHOT.jar,sha256=H5c5mfHm2WfD1VlYrS4ZJzwUnXvK4Mtl9yA-PQ9FPrk,14050
-raydp/jars/raydp-shims-spark330-1.7.0-SNAPSHOT.jar,sha256=LXXUYPPmD5MYWqK9GCXHURJzRihlmQ3vQkyOS6HkSi8,15151
-raydp/jars/raydp-shims-spark340-1.7.0-SNAPSHOT.jar,sha256=VoDsmW03ZHbGzKH6b6lTUxi_e4L45mAazC3riGzfzxQ,16004
+raydp/bin/raydp-submit,sha256=d8oSUdwKoeSTAC3EVf1TUIJfTkuI3Y_dfeuJEayHeNs,5101
+raydp/jars/raydp-1.7.0-SNAPSHOT.jar,sha256=K0taPt9or64ZPPW_8743cHe2CthwAp4BFGXhN5WTffE,287221
+raydp/jars/raydp-agent-1.7.0-SNAPSHOT.jar,sha256=CuDkDqYNH180Cr-0LdkhBMmodb1DXaUakuydtFI7Jjo,7071
+raydp/jars/raydp-shims-common-1.7.0-SNAPSHOT.jar,sha256=pEHanC2DT1wAFhodfo_0WiXSezrBkS5yRGiNoPD42Us,16000
+raydp/jars/raydp-shims-spark322-1.7.0-SNAPSHOT.jar,sha256=OSvlng_4C5HlQu3pEilOhKPTu23j6ajqf9Aq9BZMNNw,14050
+raydp/jars/raydp-shims-spark330-1.7.0-SNAPSHOT.jar,sha256=gLUKjqcZdjTjiAjR2Z2l4E7ibQcuaXTGlyWj3l3we8Q,15256
+raydp/jars/raydp-shims-spark340-1.7.0-SNAPSHOT.jar,sha256=veTSPOd3mZ_cLHzpoycfoyl2QCA5FlQ5GL9fX9sxCXM,16185
+raydp/jars/raydp-shims-spark350-1.7.0-SNAPSHOT.jar,sha256=QFBF7Dc2UZrn1wZle_aQaeR7g9NabPLfQv9E6_tL5RI,16005
 raydp/mpi/__init__.py,sha256=D7FqnoltSOe8xVkFK8gU__DmjjnC8Sis0PIKaM47AYE,4396
 raydp/mpi/constants.py,sha256=dQ88MJoHAErsbhSl5CuLHIhaHWQiR3SaxnDP60GmOlg,1122
 raydp/mpi/mpi_job.py,sha256=lQ7e9bvuhW0WacpCnHGeHwRn2poh1b1dDB0QCdiap6U,15624
 raydp/mpi/mpi_worker.py,sha256=19Taj2XXXEhpLMJb56IUpDaOfKq07npxTFL1zFVyAyA,8304
 raydp/mpi/utils.py,sha256=PnHY8f83vFal-62uaWyJAuZ-h4rEh5EIkQmxqKgH9L4,4044
 raydp/mpi/network/__init__.py,sha256=TEGVvC43kMjn54KZtmaOqO7PixOfiqUbANBCYHO1cf4,893
 raydp/mpi/network/network_pb2.py,sha256=-Eb7vh03eMHGadh4doFs6IqfJxeh1dBe3gGkHCMxVBY,15133
 raydp/mpi/network/network_pb2_grpc.py,sha256=1TCou5xPOpmvzSfKZzWKklRumDV9REnsfXjWKyYEvRw,8980
-raydp/spark/__init__.py,sha256=UkNQ9Z7tLd_Flnahg_-kQqc90XDpTZfOXg9Enh8PUGg,1361
-raydp/spark/dataset.py,sha256=OXX_xm4bj28fdaMuJJKHeWli9kKL8HMY8IzSGhTCKlk,25574
+raydp/spark/__init__.py,sha256=wU9Q3zhw-VZeagIUVk1wr6RbY3dE_QkiBGCCIge6eoU,1509
+raydp/spark/dataset.py,sha256=HsXHeDTzMHrr5EzbGtxb-EHyZDhHBpgimQRWG8NiLwk,26438
 raydp/spark/interfaces.py,sha256=GpnEvHEoySmfOjzkxpNnhgiUzI6k8wsccxDhBNPKrOc,1535
 raydp/spark/parallel_iterator_worker.py,sha256=fFOOKAnInCmOHqOkw5O61uqy0w1CjrvWk-AFHw7aL94,1141
 raydp/spark/ray_cluster.py,sha256=qKQDWXqcFWZSev7lRr6Og3YWrlGe0YhwPPuJEOWB18w,9540
 raydp/spark/ray_cluster_master.py,sha256=HgKko4f4EMysdb6G-hB0k58x3i5s02-4X-1eleYxwVE,9286
 raydp/tf/__init__.py,sha256=SuMuiiFVuBE9VcePTuHqfiKaDKlwpRiRx5bOcWeDP5g,847
-raydp/tf/estimator.py,sha256=J6RxMIWJMYx04Ajptml2J7uso1pYUabEvielvKw9oiM,13398
+raydp/tf/estimator.py,sha256=bvaX1cXySJ7mJ3ghXPACafwNzy8Ad446yoFdnkasD68,13334
 raydp/torch/__init__.py,sha256=BAl_Yx7uOZpFkwD2EeWNanCgD3TGzjuEqBawRpDROWs,853
-raydp/torch/config.py,sha256=DqwwsuURaIKdrRJ0DuhM28Q_5vcIpmtoAmJkDENRC7k,1218
-raydp/torch/estimator.py,sha256=1oR1Tu7Bf9efJpwlSGSq7Dvjpobc3qJBYanQs2W3Lvk,18693
+raydp/torch/config.py,sha256=58d8SnOJJExwuIROF8e0XZhikJVarFsz58nqpSfGSik,1436
+raydp/torch/estimator.py,sha256=d7MQyvSskFQuNxmPCsdTIuE04cZkTIYZ5Nks547T7F8,18365
 raydp/torch/torch_metrics.py,sha256=ZuT2LZbdJrEpux7MfdeMd6xgb7sepv9HP7wvz8rsAmQ,2202
 raydp/torch/torch_ml_dataset.py,sha256=Su-PoYhG1Xw2wxfBO2l5lQRNNbF2QNJWHhHxY1j1k-I,3862
 raydp/xgboost/__init__.py,sha256=KX1ofa153dtxbvWrahnOMEeDMrJzK3weLWU2aT--8kc,857
-raydp/xgboost/estimator.py,sha256=qJGfn7vWfnrC43jaFtA9qXjugq6PWLtE5ganxY_X_Vs,5889
-raydp_nightly-2023.9.19.dev0.dist-info/METADATA,sha256=OJ2pkfuhPhlpoK6If0CRkGqnojkVE5mjnmNoNRh1nSQ,10110
-raydp_nightly-2023.9.19.dev0.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
-raydp_nightly-2023.9.19.dev0.dist-info/top_level.txt,sha256=2ZCZ27XGfc3HF1QqtUdpbb0pc0rCtALdvl_IOl97wlU,6
-raydp_nightly-2023.9.19.dev0.dist-info/RECORD,,
+raydp/xgboost/estimator.py,sha256=JDV-oYdIODm-7vMqMAVLVBA14gf1bVpuPDEz1xZopbE,6022
+raydp_nightly-2024.4.10.dev0.dist-info/METADATA,sha256=ajZVF6qDrKYlsSRwM_XNjSMJ72Dy5enTwQpvrnoHeDQ,10110
+raydp_nightly-2024.4.10.dev0.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
+raydp_nightly-2024.4.10.dev0.dist-info/top_level.txt,sha256=2ZCZ27XGfc3HF1QqtUdpbb0pc0rCtALdvl_IOl97wlU,6
+raydp_nightly-2024.4.10.dev0.dist-info/RECORD,,
```

